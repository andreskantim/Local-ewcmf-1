slurmstepd: info: Setting TMPDIR to /scratch/13088128. Previous errors about TMPDIR can be discarded
dwi_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20, 10)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.48369565 -0.51938361 -0.48727056 -0.52139305 -0.48027834 -0.50605758
 -0.4943708  -0.54400884 -0.51512919 -0.54486958 -0.48885229 -0.51757007
 -0.47826974 -0.50123637 -0.4825099  -0.51745146 -0.47667175 -0.49832385
 -0.49541435 -0.52670733 -0.50536808 -0.5491004  -0.489867   -0.52086748
 -0.48867202 -0.52280929 -0.5041855  -0.53848787 -0.48293874 -0.50392049
 -0.50660103 -0.54504467 -0.51927711 -0.55658403 -0.48404653 -0.5121416
 -0.48092173 -0.50345711 -0.48992189 -0.53148829 -0.49643856 -0.52266416
 -0.5029913  -0.53869082 -0.51911409 -0.55674526 -0.50574569 -0.54058934
 -0.46206551 -0.47847259 -0.46893603 -0.4980452  -0.48928995 -0.52787211
 -0.46989309 -0.49994211 -0.4809125  -0.52274286 -0.51733585 -0.53734767
 -0.46122506 -0.4677893  -0.46664522 -0.48333846 -0.49059877 -0.51858022
 -0.46394298 -0.48741909 -0.47533698 -0.5067031  -0.51638121 -0.55374544]
[0.05465574 0.07403135 0.05235542 0.06662081 0.05306418 0.05644126
 0.06207645 0.07272962 0.04458531 0.06052895 0.04608365 0.0703046
 0.05146967 0.06532766 0.05179788 0.07202076 0.0583233  0.0609545
 0.05391954 0.06454012 0.05434628 0.08489422 0.0600836  0.05835863
 0.04707087 0.06621146 0.05592892 0.07280127 0.05644037 0.06287541
 0.05976146 0.06240033 0.05736163 0.06236398 0.05635294 0.06943212
 0.05360306 0.0619579  0.05349411 0.06049233 0.05625033 0.06396081
 0.05159553 0.07765223 0.05147423 0.05902463 0.05540267 0.06791723
 0.05819558 0.06777998 0.05559195 0.06888833 0.05429443 0.06852869
 0.05483069 0.06907873 0.05505269 0.07270517 0.05175035 0.05494138
 0.05789133 0.05906195 0.05554742 0.06497144 0.05378139 0.06451217
 0.05484009 0.05893825 0.05818482 0.06967469 0.05100593 0.07229179]
[18 53 20 55 12 41 28 66 45 67 23 49 10 34 15 48  9 32 29 59 39 69 25 54
 22 58 38 63 16 37 42 68 52 71 19 44 14 36 26 61 30 56 35 64 51 72 40 65
  2 11  6 31 24 60  7 33 13 57 47 62  1  5  4 17 27 50  3 21  8 43 46 70]
dwi_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20, 10)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.43299665 -0.44992022 -0.439036   -0.45805319 -0.4245338  -0.45109619
 -0.45504864 -0.47041353 -0.45571852 -0.48263238 -0.43895488 -0.45628673
 -0.43388948 -0.44628094 -0.43942245 -0.45858473 -0.42973227 -0.45792154
 -0.44061177 -0.46436254 -0.45816791 -0.4839557  -0.43773689 -0.46211383
 -0.4430708  -0.46860728 -0.45109482 -0.47492409 -0.45202607 -0.45065888
 -0.4596924  -0.49163246 -0.47990351 -0.50681717 -0.44706871 -0.45716412
 -0.43475832 -0.45813746 -0.44236591 -0.47195409 -0.46583136 -0.46390169
 -0.45602354 -0.47665857 -0.46556763 -0.49936271 -0.45124989 -0.47074714
 -0.42101678 -0.42853531 -0.43446704 -0.45311232 -0.45085161 -0.47019251
 -0.43547455 -0.45243446 -0.43896733 -0.46898879 -0.47593144 -0.47769874
 -0.4171741  -0.42076325 -0.42362129 -0.43749338 -0.45683679 -0.47617558
 -0.42659805 -0.44146075 -0.43518943 -0.45165339 -0.46974902 -0.48584194]
[0.03963442 0.03843453 0.03893035 0.03410375 0.04067649 0.05331234
 0.03559032 0.02665322 0.04935249 0.03779247 0.03810313 0.04514492
 0.03967818 0.03308256 0.04370178 0.03950649 0.03593757 0.03298503
 0.04220773 0.03832001 0.0449628  0.03538214 0.04125505 0.03566503
 0.03932102 0.03472888 0.04295589 0.03991012 0.0448263  0.03353505
 0.04878081 0.04437076 0.04041025 0.03155607 0.03522945 0.02154913
 0.03860702 0.0311022  0.04699538 0.03624159 0.03898469 0.03824809
 0.03999721 0.03752521 0.04118729 0.03123852 0.03217862 0.03185068
 0.0341295  0.04123122 0.03896724 0.04191434 0.04282419 0.04131706
 0.04266319 0.03407338 0.04404534 0.04074697 0.05344638 0.03518751
 0.03521159 0.03568487 0.0394755  0.03849841 0.04090719 0.05937536
 0.03584632 0.03091524 0.04159445 0.03897643 0.04690242 0.02997227]
[ 9 27 19 44  5 31 37 58 38 67 17 40 10 25 20 47  8 43 21 51 46 68 16 49
 24 54 30 61 34 28 48 70 66 72 26 42 12 45 23 60 53 50 39 64 52 71 32 59
  3  7 11 36 29 57 14 35 18 55 62 65  1  2  4 15 41 63  6 22 13 33 56 69]
wind_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20, 10)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-2.38606389 -2.45344566 -2.42504602 -2.51346662 -2.3849229  -2.53101958
 -2.43555326 -2.58690864 -2.43277585 -2.63568361 -2.39113884 -2.57502098
 -2.40364568 -2.40618331 -2.4307951  -2.50452412 -2.35231754 -2.48049452
 -2.41273978 -2.50104313 -2.44899426 -2.63639749 -2.45495397 -2.54705246
 -2.4626392  -2.70212653 -2.53355144 -2.70476753 -2.48032615 -2.65069517
 -2.57741989 -2.76607347 -2.63532722 -2.81751841 -2.50357831 -2.62384377
 -2.43516224 -2.62504451 -2.53258369 -2.6965006  -2.51763842 -2.68213512
 -2.51851296 -2.75808232 -2.55458951 -2.86647561 -2.5204276  -2.69120322
 -2.36007003 -2.45632878 -2.36182262 -2.47942164 -2.44873728 -2.61894317
 -2.38328236 -2.53509997 -2.44238764 -2.64854502 -2.53331941 -2.6894447
 -2.39758937 -2.464616   -2.36750215 -2.47328514 -2.47472424 -2.58742139
 -2.3714687  -2.470538   -2.38710425 -2.60641521 -2.56121361 -2.74627985]
[0.39659645 0.36619193 0.40020685 0.36720732 0.39581901 0.50388086
 0.40881984 0.3947991  0.4208067  0.34059732 0.40919129 0.42994733
 0.39910739 0.36909466 0.49344275 0.38288667 0.41178009 0.40039221
 0.41951157 0.38828218 0.43827285 0.41497999 0.39517693 0.35832397
 0.44969949 0.41682533 0.44300997 0.33107937 0.4543634  0.38164581
 0.49149636 0.37930117 0.41012752 0.36852519 0.43626849 0.39670599
 0.46745257 0.41207716 0.52564222 0.37051164 0.44961226 0.35816529
 0.48629142 0.43486134 0.46258417 0.35907956 0.43120116 0.35854389
 0.41956472 0.37850754 0.41630361 0.33119579 0.42888642 0.33876045
 0.4366184  0.39448228 0.44525356 0.35117007 0.42389388 0.32516799
 0.53509409 0.49493593 0.44582189 0.37048627 0.40858187 0.37386729
 0.43366018 0.3593287  0.40510177 0.34178541 0.44367628 0.3452683 ]
[ 8 23 15 37  7 41 19 51 17 58 10 49 12 13 16 36  1 33 14 34 22 59 24 46
 26 66 44 67 32 61 50 70 57 71 35 55 18 56 42 65 38 62 39 69 47 72 40 64
  2 25  3 31 21 54  6 45 20 60 43 63 11 27  4 29 30 52  5 28  9 53 48 68]
wind_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20, 10)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-2.06024508 -2.16947974 -2.11146194 -2.19321126 -2.12106136 -2.24566648
 -2.13187708 -2.23629767 -2.14251284 -2.34442013 -2.10814044 -2.22736687
 -2.04750195 -2.09876618 -2.10063279 -2.20395371 -2.07669995 -2.14225185
 -2.10408666 -2.24552054 -2.12888993 -2.32389741 -2.14644432 -2.29188947
 -2.15456987 -2.32428586 -2.16404668 -2.30516776 -2.17721765 -2.28219508
 -2.22552028 -2.41944467 -2.28803286 -2.48677111 -2.15291941 -2.31564751
 -2.13859622 -2.30640327 -2.20608928 -2.34429401 -2.18233058 -2.32663312
 -2.23540437 -2.33454457 -2.25346953 -2.45989195 -2.2047193  -2.32486862
 -2.06360619 -2.06959619 -2.07185185 -2.12862576 -2.18548473 -2.32098756
 -2.08696626 -2.15285116 -2.13545258 -2.23021613 -2.25025638 -2.36009194
 -2.06894736 -2.1072202  -2.05365913 -2.1010834  -2.15905758 -2.26660094
 -2.06960754 -2.14076248 -2.10714178 -2.20859437 -2.23684114 -2.34492687]
[0.42654854 0.39272274 0.44110645 0.41381241 0.44290899 0.4568635
 0.43116931 0.41767479 0.42094146 0.50083564 0.43132761 0.38829892
 0.41568017 0.42265198 0.42908055 0.42823352 0.47013058 0.42102287
 0.43341133 0.42124918 0.4755535  0.42946307 0.43115565 0.45529763
 0.45418442 0.45316464 0.42502197 0.39945299 0.4735767  0.37411232
 0.4755529  0.45112706 0.44916745 0.36424522 0.43112154 0.4076731
 0.46816172 0.37490386 0.52243201 0.42903694 0.42794631 0.45149246
 0.45281824 0.42320653 0.48060327 0.4111965  0.42961054 0.38233816
 0.43750897 0.39131658 0.43423543 0.35794789 0.43804987 0.34099514
 0.45128966 0.39599345 0.44904678 0.38980379 0.48332367 0.30547073
 0.47125213 0.40532291 0.44437771 0.38787024 0.43957772 0.35473115
 0.44395842 0.36680224 0.43394814 0.39506731 0.48999283 0.317418  ]
[ 3 34 18 38 19 50 22 47 27 67 17 44  1 11 12 39  9 26 14 49 21 61 28 56
 31 62 33 57 35 54 43 70 55 72 30 59 24 58 41 66 36 64 46 65 52 71 40 63
  4  6  8 20 37 60 10 29 23 45 51 69  5 16  2 13 32 53  7 25 15 42 48 68]
shww_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20, 10)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.94378008 -0.9650477  -0.9636332  -0.98377107 -1.01318851 -1.01653387
 -0.99433524 -1.01982366 -1.00862896 -1.04277911 -1.01764479 -1.00440305
 -0.93779931 -0.97335705 -0.96373838 -0.98985131 -0.93954368 -1.01708872
 -0.95511386 -1.03105598 -1.00719997 -1.06763733 -1.00651125 -1.05358409
 -0.98997022 -1.04826282 -1.0323517  -1.0495228  -0.97262175 -1.03447197
 -1.03262515 -1.07050156 -1.08653782 -1.11078125 -1.00372076 -1.05750207
 -0.97794143 -1.02679687 -0.99199412 -1.04551675 -1.00761693 -1.05684553
 -1.03448725 -1.07556416 -1.05937736 -1.14389755 -1.00597933 -1.06027152
 -0.916283   -0.90746851 -0.93153805 -0.94817881 -0.97804123 -1.03128447
 -0.93393077 -0.95836057 -0.96578823 -1.00719351 -1.00739239 -1.04288846
 -0.91532112 -0.90796773 -0.93619484 -0.92486779 -0.97742953 -0.9989899
 -0.92544889 -0.94452933 -0.95717647 -0.97692185 -0.99218886 -1.03901331]
[0.40706407 0.40732897 0.41800282 0.40696259 0.46567742 0.4257039
 0.44999343 0.43249366 0.45151857 0.42258673 0.53054358 0.43486997
 0.3981251  0.40069845 0.42413417 0.41230393 0.40934578 0.46337494
 0.40124734 0.43860258 0.46505906 0.46409178 0.46444759 0.46359502
 0.42457412 0.36597074 0.39958431 0.38392369 0.41057512 0.39220606
 0.44460279 0.42537269 0.42615259 0.38898063 0.4015947  0.39384753
 0.37450335 0.37401294 0.4130742  0.37618249 0.42319475 0.40978684
 0.42825003 0.39377418 0.43929602 0.41428198 0.41873351 0.40566094
 0.40513988 0.37206474 0.4076308  0.40747614 0.44859361 0.46743631
 0.40649436 0.3951327  0.45340434 0.44008189 0.44908675 0.4251399
 0.40270225 0.38962382 0.41241868 0.39431878 0.44379156 0.42328384
 0.39911557 0.40469455 0.43774443 0.43320631 0.42544435 0.44418318]
[12 20 18 28 44 45 33 48 43 57 47 36 10 23 19 29 11 46 15 50 40 67 38 62
 30 60 52 61 22 54 53 68 70 71 35 64 26 49 31 59 42 63 55 69 65 72 37 66
  4  1  7 14 27 51  8 17 21 39 41 58  3  2  9  5 25 34  6 13 16 24 32 56]
shww_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20, 10)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.72083795 -0.76114353 -0.73285886 -0.75444952 -0.74247489 -0.78257095
 -0.73982134 -0.78834318 -0.75026454 -0.80420425 -0.74661547 -0.77643988
 -0.72093994 -0.73363802 -0.73991695 -0.76936636 -0.77104421 -0.74671593
 -0.72935174 -0.75854095 -0.73996699 -0.77568198 -0.75775925 -0.7794582
 -0.74228436 -0.79538515 -0.75587663 -0.79908325 -0.76201006 -0.76163743
 -0.75940729 -0.85464931 -0.79601551 -0.83414874 -0.7779852  -0.79235662
 -0.73353533 -0.76726297 -0.76687484 -0.79830315 -0.74995486 -0.78995354
 -0.75787898 -0.81989045 -0.7682253  -0.81895948 -0.76904123 -0.78635578
 -0.69075223 -0.70053337 -0.71593061 -0.7261397  -0.76118725 -0.75223857
 -0.71755527 -0.70631809 -0.73751586 -0.75520295 -0.77282349 -0.78365879
 -0.69038002 -0.68347191 -0.70898298 -0.70270261 -0.73488447 -0.75889198
 -0.70243548 -0.70407912 -0.72961561 -0.74425402 -0.74891956 -0.77518847]
[0.35590711 0.41012977 0.34636163 0.38366696 0.37583855 0.41849752
 0.35811481 0.36351828 0.3292836  0.39550658 0.35146335 0.3452219
 0.35373653 0.36515997 0.34428051 0.38004829 0.40412326 0.35449685
 0.34209031 0.37018516 0.33754924 0.37015651 0.34987046 0.43148816
 0.32651017 0.33366157 0.34730114 0.36031171 0.35255937 0.3376096
 0.36850137 0.31448938 0.3774697  0.32028453 0.36205659 0.34509029
 0.31668548 0.29406038 0.35342994 0.32196959 0.34052947 0.34599645
 0.34952945 0.31642275 0.35488092 0.32791142 0.36508673 0.32494102
 0.33155404 0.31271857 0.36558192 0.35789622 0.38384901 0.34354391
 0.35668813 0.35149555 0.37991572 0.3827371  0.36767486 0.37255701
 0.3307722  0.2988844  0.3415868  0.32642978 0.35070299 0.34162298
 0.33750546 0.33786373 0.36950762 0.36470827 0.37341112 0.36065967]
[12 42 17 34 26 58 22 61 32 68 28 55 13 19 23 50 51 29 15 39 24 54 37 57
 25 64 36 67 45 44 41 72 65 71 56 63 18 47 46 66 31 62 38 70 48 69 49 60
  3  4 10 14 43 33 11  8 21 35 52 59  2  1  9  6 20 40  5  7 16 27 30 53]
mdts_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20, 10)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.10145544 -0.0957958  -0.10139759 -0.09435117 -0.09672992 -0.09287719
 -0.10162156 -0.10254844 -0.10436723 -0.09885154 -0.09130639 -0.09415414
 -0.09965936 -0.09392608 -0.09924244 -0.09773509 -0.08970696 -0.09034479
 -0.10464271 -0.09822813 -0.10167961 -0.10253571 -0.0955889  -0.09779286
 -0.09604886 -0.09240451 -0.09968172 -0.09755417 -0.09774964 -0.09308108
 -0.10136998 -0.10268926 -0.10676879 -0.10172095 -0.09702549 -0.10355865
 -0.09670193 -0.0925968  -0.10097696 -0.09783224 -0.09550312 -0.09804302
 -0.10479677 -0.10060642 -0.1050056  -0.10023785 -0.09594871 -0.0984319
 -0.09248625 -0.09121781 -0.09524639 -0.09027386 -0.09737723 -0.09461725
 -0.09689145 -0.09095825 -0.09889463 -0.09634136 -0.10651151 -0.09796444
 -0.09119076 -0.08866263 -0.0935761  -0.08928691 -0.09565663 -0.0966049
 -0.09527171 -0.08891951 -0.09487131 -0.0914401  -0.10390221 -0.09537187]
[0.05199939 0.04651092 0.05039365 0.04857164 0.0616525  0.04765623
 0.04943546 0.04676973 0.04776124 0.04314658 0.05556042 0.0535778
 0.04988352 0.04220365 0.04983441 0.04624565 0.05354822 0.05013557
 0.05020551 0.04067514 0.04563736 0.04136842 0.04993151 0.05089232
 0.05059764 0.0411933  0.04925708 0.04366235 0.04964144 0.04755061
 0.048252   0.04493827 0.04668411 0.04399612 0.05308955 0.04458854
 0.05179677 0.04200729 0.05174872 0.04279766 0.05117601 0.04329466
 0.04540946 0.04694987 0.04984147 0.04163379 0.05062473 0.0429869
 0.05302321 0.04840945 0.05104576 0.04608414 0.0512672  0.04246427
 0.05184187 0.04480752 0.05214427 0.04708076 0.04683828 0.04372545
 0.05255998 0.04768736 0.0512898  0.04371423 0.05192923 0.04942822
 0.05213212 0.04555771 0.05150672 0.04548471 0.04523483 0.0449828 ]
[58 29 57 20 35 15 59 63 67 48 10 19 51 18 50 40  4  6 68 46 60 62 27 42
 31 12 52 39 41 16 56 64 72 61 37 65 34 14 55 43 26 45 69 54 70 53 30 47
 13  9 23  5 38 21 36  7 49 32 71 44  8  1 17  3 28 33 24  2 22 11 66 25]
mdts_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20, 10)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.11722943 -0.1117485  -0.11578535 -0.11161618 -0.10215387 -0.09913622
 -0.12125511 -0.11936103 -0.12641622 -0.11993591 -0.09984001 -0.10366835
 -0.1130894  -0.11149473 -0.1130155  -0.11484116 -0.10292808 -0.10827304
 -0.11709198 -0.11693048 -0.12080155 -0.11973572 -0.10429682 -0.10630589
 -0.11702599 -0.11406477 -0.12953312 -0.12025938 -0.11416048 -0.11598119
 -0.1291151  -0.12536303 -0.13081586 -0.11989825 -0.113411   -0.11022914
 -0.11520818 -0.1138585  -0.11761089 -0.11817435 -0.11835487 -0.11795138
 -0.11754707 -0.12522202 -0.14458133 -0.12791202 -0.11969882 -0.11342732
 -0.10795499 -0.10131772 -0.11113863 -0.10838618 -0.12096581 -0.11045498
 -0.11319072 -0.10952248 -0.11700507 -0.1145022  -0.13534242 -0.11682166
 -0.1054524  -0.09869444 -0.10917609 -0.10338425 -0.12876962 -0.11083347
 -0.1113295  -0.10500576 -0.11496831 -0.10754675 -0.12969325 -0.11699782]
[0.04265081 0.04185391 0.04448489 0.04317183 0.04613504 0.04456095
 0.04535819 0.04662836 0.03861883 0.04586748 0.04995894 0.04935276
 0.04085515 0.04059461 0.04493686 0.04344121 0.05304664 0.04275561
 0.04157654 0.04082646 0.04325703 0.04777441 0.05046861 0.04194416
 0.04347003 0.04265179 0.04251912 0.04374743 0.04080584 0.04339729
 0.04218003 0.04235208 0.03819717 0.04446819 0.04598818 0.04393918
 0.04047959 0.04163313 0.04097443 0.04251263 0.04051836 0.04085162
 0.04027372 0.04546344 0.03985245 0.04107295 0.04173672 0.03974888
 0.04542976 0.0440625  0.04342052 0.04298745 0.0432974  0.04623057
 0.04452308 0.03821555 0.04436927 0.04552709 0.03721693 0.04313594
 0.04507874 0.04289544 0.04654257 0.04334038 0.04014234 0.04031981
 0.04505409 0.04323791 0.03888169 0.04120303 0.04045262 0.04276377]
[47 26 39 25  5  2 61 53 64 57  3  8 28 24 27 36  6 15 46 42 59 55  9 12
 45 33 68 58 34 40 67 63 70 56 30 19 38 32 49 51 52 50 48 62 72 65 54 31
 14  4 22 16 60 20 29 18 44 35 71 41 11  1 17  7 66 21 23 10 37 13 69 43]
shts_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20, 10)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.57267444 -0.59634661 -0.5610866  -0.60517444 -0.60012565 -0.60531
 -0.57293596 -0.62910609 -0.59637055 -0.63580831 -0.57408413 -0.6897625
 -0.55692055 -0.59727738 -0.58165295 -0.63585521 -0.58698834 -0.60458474
 -0.57498629 -0.6297172  -0.59874797 -0.62174245 -0.59731071 -0.60976832
 -0.61545775 -0.62274852 -0.60507621 -0.66060152 -0.64315489 -0.65719658
 -0.6314004  -0.66231607 -0.6510676  -0.68901267 -0.64909474 -0.65501823
 -0.59319091 -0.62467404 -0.63148049 -0.64857292 -0.6154871  -0.6537688
 -0.604113   -0.65720827 -0.62028932 -0.66631668 -0.63745114 -0.65249162
 -0.55271614 -0.57241307 -0.55300038 -0.58457952 -0.59497286 -0.62256922
 -0.56252162 -0.60557291 -0.56638129 -0.6337971  -0.60587006 -0.65008117
 -0.55100346 -0.57710891 -0.55163689 -0.57232488 -0.60076291 -0.62064395
 -0.55387749 -0.58209691 -0.56441051 -0.6101975  -0.61773144 -0.64261747]
[0.15744769 0.15240519 0.16912696 0.14987148 0.18143234 0.16418401
 0.1636692  0.16604789 0.1797158  0.1799335  0.17919786 0.19211727
 0.15759873 0.15463374 0.1564419  0.18955425 0.18546035 0.1630403
 0.1641474  0.16126341 0.16540908 0.15812472 0.18953251 0.18108315
 0.16229124 0.16942561 0.18100713 0.16237873 0.19809268 0.17287607
 0.17544297 0.17305095 0.18487584 0.19432016 0.20068089 0.18695095
 0.16244914 0.14112654 0.18234352 0.18091704 0.18636272 0.17049946
 0.15416762 0.17431987 0.18216348 0.16902257 0.19366612 0.16905078
 0.1614954  0.15727604 0.16583487 0.16760353 0.18796298 0.17212723
 0.18025856 0.17374147 0.17331974 0.19711922 0.17863456 0.18414774
 0.15460851 0.15940386 0.16919155 0.15736684 0.18506022 0.17936173
 0.1647697  0.15392853 0.17427073 0.17341235 0.18514829 0.17422192]
[13 24  7 34 29 35 14 49 25 54 15 72  6 26 18 55 21 32 16 50 28 45 27 38
 40 47 33 68 58 66 51 69 62 71 60 65 22 48 52 59 41 64 31 67 43 70 56 63
  3 12  4 20 23 46  8 36 10 53 37 61  1 17  2 11 30 44  5 19  9 39 42 57]
shts_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20, 10)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.51438875 -0.544195   -0.50844614 -0.55572331 -0.52857064 -0.55346605
 -0.51309105 -0.56554215 -0.51453519 -0.55318753 -0.54563352 -0.55428578
 -0.50601562 -0.52838926 -0.51087926 -0.52759383 -0.50294476 -0.53367016
 -0.51041879 -0.569657   -0.51326452 -0.57007575 -0.53104759 -0.54180883
 -0.5352962  -0.55684964 -0.54096423 -0.57349979 -0.56996791 -0.57095085
 -0.5440431  -0.58316079 -0.59210026 -0.62602608 -0.5652189  -0.57061707
 -0.53647634 -0.55125795 -0.54605755 -0.55127612 -0.56346185 -0.59019124
 -0.54841491 -0.57522282 -0.55517199 -0.59560607 -0.5607508  -0.57353618
 -0.49618106 -0.50873865 -0.49560462 -0.52558709 -0.52552049 -0.53733636
 -0.49710328 -0.52482915 -0.51030078 -0.53052911 -0.53266993 -0.56350495
 -0.49620153 -0.51234927 -0.48836622 -0.51639517 -0.52784891 -0.54138633
 -0.50067047 -0.51637027 -0.5038115  -0.54770809 -0.53949997 -0.56955557]
[0.13006739 0.13376417 0.12671598 0.12049344 0.14408572 0.12228431
 0.13244506 0.14442524 0.1316741  0.13439304 0.16268548 0.11778375
 0.11733526 0.10860804 0.12774982 0.12122151 0.12325824 0.13874305
 0.13255471 0.12427114 0.13249422 0.13526087 0.14405779 0.13556427
 0.12449681 0.10913936 0.12543751 0.10704743 0.13609396 0.13596714
 0.14032301 0.12626038 0.16259001 0.14347643 0.13259071 0.10991942
 0.11404487 0.10460817 0.13134911 0.11926539 0.13682111 0.11856681
 0.13607765 0.13026049 0.13902566 0.12792866 0.13767336 0.14398245
 0.12198922 0.12233973 0.13596544 0.12282212 0.1418202  0.12298945
 0.13350092 0.12266359 0.13867342 0.13305335 0.13588588 0.13251105
 0.12430793 0.11434325 0.11912509 0.11364011 0.14133974 0.13621067
 0.13306495 0.12396301 0.14061462 0.14019914 0.14796086 0.13719867]
[18 41 10 52 28 49 16 58 19 48 42 50  9 27 14 25  7 32 13 60 17 62 30 39
 33 53 37 65 61 64 40 68 70 72 57 63 34 46 43 47 55 69 45 67 51 71 54 66
  3 11  2 24 23 35  5 22 12 29 31 56  4 15  1 21 26 38  6 20  8 44 36 59]

*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 13088128)                   *
*                                                                           *
*****************************************************************************

Job ID: 13088128
Cluster: finisterrae3
User/Group: curso342/ulc
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 32
CPU Utilized: 4-06:25:39
CPU Efficiency: 97.69% of 4-08:50:40 core-walltime
Job Wall-clock time: 03:16:35
Memory Utilized: 15.92 GB
Memory Efficiency: 49.76% of 32.00 GB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************

