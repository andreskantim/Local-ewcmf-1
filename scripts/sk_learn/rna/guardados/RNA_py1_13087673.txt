slurmstepd: info: Setting TMPDIR to /scratch/13087673. Previous errors about TMPDIR can be discarded
dwi_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(10,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.46636275 -0.47481205 -0.4674015  -0.47239068 -0.471873   -0.48507182
 -0.46421321 -0.47529756 -0.46257651 -0.47762416 -0.46777425 -0.4828119
 -0.46624913 -0.46759157 -0.46343108 -0.47423702 -0.47392517 -0.48355956
 -0.4640555  -0.46981624 -0.46418771 -0.47071248 -0.47376373 -0.48368567
 -0.46583282 -0.47272768 -0.46442512 -0.47789979 -0.4712262  -0.49075008
 -0.46821345 -0.47835361 -0.46828129 -0.48504803 -0.47956651 -0.49159042
 -0.46494322 -0.47348857 -0.46728416 -0.47945493 -0.48088021 -0.48771428
 -0.46759342 -0.47937639 -0.4703358  -0.47711303 -0.48304244 -0.49197067
 -0.4632505  -0.46917793 -0.46543014 -0.47056114 -0.47122629 -0.48619463
 -0.46523088 -0.47505346 -0.46593083 -0.47515063 -0.47922642 -0.48125408
 -0.46295219 -0.46550006 -0.46482763 -0.46686465 -0.46693944 -0.4793246
 -0.46344935 -0.46914622 -0.46617296 -0.47405723 -0.47657779 -0.4851684 ]
[0.05211346 0.0640379  0.05187619 0.06727881 0.06281135 0.06680835
 0.05575377 0.06374544 0.05468647 0.06346341 0.05255977 0.07264912
 0.05773009 0.06485822 0.05942402 0.06279968 0.06119044 0.06736529
 0.0567264  0.0610924  0.05772406 0.06356259 0.05520996 0.06290731
 0.0538926  0.05883414 0.05657335 0.06424373 0.06476895 0.05642364
 0.05156048 0.06120746 0.05437271 0.0575755  0.05202016 0.05774066
 0.0553356  0.05585608 0.05394406 0.05878039 0.05542204 0.05849177
 0.05433117 0.05869093 0.0542604  0.06124806 0.053601   0.06029935
 0.05358033 0.05843391 0.05617999 0.06225926 0.0548407  0.05373831
 0.05503094 0.05472652 0.05391427 0.06258561 0.04723472 0.06004326
 0.05405812 0.0571404  0.05440978 0.05799574 0.05489644 0.05828538
 0.05287943 0.0599222  0.05554669 0.06018146 0.05326299 0.05829423]
[19 45 23 38 37 66  8 48  1 51 26 61 18 24  4 44 42 63  6 31  7 34 41 64
 15 39  9 52 35 70 27 53 28 65 58 71 11 40 22 57 59 69 25 56 32 50 62 72
  3 30 13 33 36 68 12 46 16 47 54 60  2 14 10 20 21 55  5 29 17 43 49 67]
dwi_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(10,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.42148491 -0.42007745 -0.42089581 -0.42119848 -0.42413131 -0.42727214
 -0.42252651 -0.42070364 -0.42582557 -0.41850832 -0.43200678 -0.43919662
 -0.42336134 -0.42338124 -0.4261863  -0.42911102 -0.4256128  -0.42816608
 -0.42056154 -0.42100812 -0.42386911 -0.4199124  -0.42717684 -0.4286375
 -0.42013019 -0.42706073 -0.42197667 -0.42550553 -0.43474775 -0.43742184
 -0.42465855 -0.42724444 -0.42316028 -0.425661   -0.43541557 -0.44263972
 -0.42282044 -0.42320544 -0.42686597 -0.42683832 -0.43205311 -0.44672891
 -0.42040615 -0.42650587 -0.4264075  -0.42815407 -0.43326554 -0.43964114
 -0.41992865 -0.41948208 -0.42298425 -0.42195175 -0.4349249  -0.43288767
 -0.42042438 -0.41845871 -0.42205084 -0.4225361  -0.43454939 -0.43781535
 -0.41793909 -0.41717833 -0.41989515 -0.4186003  -0.42786326 -0.42418576
 -0.41749671 -0.41789417 -0.41716889 -0.41991638 -0.43417003 -0.43725429]
[0.03398872 0.03438139 0.03366533 0.03482838 0.04142712 0.04397048
 0.03131854 0.03388417 0.03631743 0.03676916 0.05453269 0.05788175
 0.03745912 0.03524512 0.03636439 0.03975654 0.03237895 0.04169786
 0.03646384 0.03482149 0.03736374 0.03615087 0.04734822 0.02666881
 0.03542517 0.03426711 0.03457556 0.03457969 0.0357858  0.04196115
 0.03344888 0.03755521 0.03830604 0.0370725  0.0387832  0.03543627
 0.0372373  0.03264329 0.03707253 0.03892841 0.03186022 0.03775467
 0.034854   0.03716692 0.03575876 0.03279373 0.03826933 0.03315887
 0.03941426 0.03346037 0.03944419 0.03295827 0.03397804 0.03324698
 0.03660484 0.03602483 0.0368536  0.03375016 0.03485602 0.03818157
 0.03607799 0.0390707  0.03471777 0.03856901 0.03388568 0.03227544
 0.03639275 0.03545818 0.03521609 0.03503585 0.03545983 0.03245842]
[23 14 20 22 36 51 27 19 42  7 57 69 33 34 43 56 40 54 18 21 35 11 49 55
 15 48 25 39 63 67 38 50 31 41 65 71 29 32 47 46 58 72 16 45 44 53 60 70
 13  9 30 24 64 59 17  6 26 28 62 68  5  2 10  8 52 37  3  4  1 12 61 66]
wind_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(10,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-2.38852115 -2.43643274 -2.34167581 -2.40908026 -2.33742578 -2.39432759
 -2.33712727 -2.41287624 -2.32886375 -2.41809653 -2.3491034  -2.45070631
 -2.44930998 -2.49028688 -2.38382804 -2.42353375 -2.36017946 -2.47777863
 -2.37454942 -2.42172283 -2.33812812 -2.44675432 -2.35441765 -2.39338232
 -2.36223459 -2.45399795 -2.3862995  -2.43237891 -2.4238469  -2.61377148
 -2.36663576 -2.39983704 -2.38147395 -2.47034817 -2.44306301 -2.62049957
 -2.39881534 -2.40527719 -2.37863029 -2.43918577 -2.49078531 -2.58191931
 -2.37321143 -2.43218325 -2.34637165 -2.46207043 -2.48316823 -2.59463391
 -2.35793429 -2.43788423 -2.35439958 -2.42169044 -2.44425752 -2.57435446
 -2.34016191 -2.40281462 -2.34388114 -2.46854392 -2.45634053 -2.6167084
 -2.41596277 -2.48022109 -2.34916223 -2.43691229 -2.41379422 -2.55731896
 -2.35424446 -2.41607324 -2.35245658 -2.46023466 -2.39937155 -2.56004571]
[0.3888915  0.38551185 0.38813756 0.36221968 0.45044965 0.41404617
 0.3938211  0.39321232 0.40600891 0.39710104 0.51085168 0.32922809
 0.42095788 0.3924722  0.42165691 0.35896286 0.37943164 0.371467
 0.37924289 0.3995169  0.38742324 0.38419151 0.41139043 0.34680554
 0.43542413 0.34638447 0.42304896 0.383556   0.42796491 0.40089439
 0.44275775 0.35970588 0.44381464 0.32594174 0.43509211 0.44218154
 0.46395279 0.40147066 0.44269139 0.35371068 0.46294877 0.35312163
 0.41676497 0.36399358 0.42046795 0.40157533 0.52808207 0.35445622
 0.43642788 0.39280776 0.42450941 0.37693495 0.41326135 0.38194173
 0.42057334 0.37373976 0.40710874 0.36393614 0.44993759 0.32512059
 0.51753931 0.4610713  0.43643402 0.37705414 0.41404149 0.35798995
 0.43390251 0.37630306 0.42446342 0.35892708 0.39523572 0.34556287]
[25 45  6 33  3 27  2 34  1 38  9 53 52 63 23 41 16 60 20 40  4 51 14 26
 17 54 24 44 42 70 18 30 22 59 49 72 28 32 21 48 64 68 19 43  8 57 62 69
 15 47 13 39 50 67  5 31  7 58 55 71 36 61 10 46 35 65 12 37 11 56 29 66]
wind_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(10,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-2.05479298 -2.07228641 -2.03430003 -2.09689314 -2.04143166 -2.16298664
 -2.05025329 -2.11088436 -2.03046511 -2.09791183 -2.01802207 -2.10558637
 -2.09583695 -2.11220061 -2.06645496 -2.10896709 -2.0396209  -2.11819439
 -2.04502365 -2.08849698 -2.04494845 -2.10489202 -2.04431666 -2.10424177
 -2.05726785 -2.11917027 -2.06323455 -2.12531971 -2.15203189 -2.26326357
 -2.04809396 -2.13805499 -2.04969934 -2.16656403 -2.13720039 -2.27781391
 -2.05078135 -2.12376974 -2.05378236 -2.15488672 -2.15666802 -2.24253925
 -2.06926143 -2.12241222 -2.08544572 -2.12076958 -2.17853155 -2.24317394
 -2.04565239 -2.10592211 -2.03552472 -2.09734366 -2.11616956 -2.21482821
 -2.02692207 -2.0931955  -2.03935244 -2.10001325 -2.0969914  -2.19531366
 -2.07459919 -2.11415648 -2.04537876 -2.1035605  -2.0448934  -2.17196473
 -2.03266508 -2.09278917 -2.04669953 -2.09473376 -2.09612621 -2.24182534]
[0.42549299 0.40885999 0.42376211 0.39314978 0.41397347 0.41743699
 0.43651045 0.42053937 0.42285965 0.41245643 0.40989815 0.43295343
 0.42037762 0.40138182 0.4239775  0.40026295 0.42105188 0.42343281
 0.42469093 0.3901602  0.44405071 0.3995358  0.42463143 0.37319482
 0.42373231 0.39065782 0.44209058 0.36872274 0.42961566 0.38916651
 0.43481145 0.36905432 0.41296077 0.40284873 0.42256402 0.41567245
 0.45317282 0.38542519 0.45269593 0.3874652  0.45171143 0.37177141
 0.45364276 0.3901777  0.45366645 0.37658899 0.51168371 0.40588536
 0.47592101 0.40812857 0.43838519 0.40128104 0.46572506 0.41197424
 0.45454168 0.38162002 0.4458614  0.37930574 0.42544498 0.37854092
 0.48470358 0.45906865 0.44001144 0.38735801 0.42628327 0.40032005
 0.43541707 0.40215531 0.43847889 0.40086514 0.43913679 0.37943412]
[22 27  5 36  9 62 19 47  3 39  1 44 34 48 25 46  8 51 13 30 12 43 10 42
 23 52 24 56 59 71 17 58 18 63 57 72 20 55 21 60 61 69 26 54 29 53 65 70
 15 45  6 38 50 67  2 32  7 40 37 66 28 49 14 41 11 64  4 31 16 33 35 68]
shww_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(10,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.89959463 -0.92341014 -0.91678888 -0.9338407  -0.92622316 -0.94976655
 -0.92423736 -0.94522385 -0.90582352 -0.92355641 -0.90747271 -0.96633961
 -0.91122131 -0.91301738 -0.90495856 -0.91159248 -0.92528624 -0.9418576
 -0.9015646  -0.91400699 -0.90848195 -0.92352472 -0.90930818 -0.94649796
 -0.9272307  -0.96013745 -0.92045072 -0.97196793 -1.00001386 -1.06381826
 -0.929564   -0.95825744 -0.9362988  -0.97235152 -0.99108983 -1.06790125
 -0.9426567  -0.94155849 -0.9048904  -0.95316779 -0.97974978 -1.06942208
 -0.92200437 -0.9699214  -0.90957754 -0.94851253 -0.99944879 -1.03565521
 -0.90681926 -0.90741902 -0.90058588 -0.93273363 -0.92565689 -0.97576679
 -0.90184204 -0.92382456 -0.90963445 -0.9373346  -0.94518066 -0.97609885
 -0.93205517 -0.92633223 -0.91937497 -0.91825251 -0.90594658 -0.94743172
 -0.90420975 -0.91955708 -0.90091812 -0.92744593 -0.94462987 -0.96830137]
[0.37801486 0.36444788 0.3873615  0.38196208 0.40433029 0.39343032
 0.3855982  0.37878507 0.37704712 0.36485019 0.37950841 0.43994576
 0.37880655 0.36227402 0.37560392 0.36491786 0.39272861 0.39672365
 0.38227823 0.36736818 0.38253425 0.36326407 0.40498475 0.40052042
 0.36436082 0.36000308 0.38470758 0.35476208 0.46289126 0.40457159
 0.40188624 0.37276168 0.38518362 0.39973477 0.41747028 0.36340946
 0.3885236  0.35552193 0.37132039 0.35190588 0.3659571  0.38720595
 0.37464284 0.37594203 0.37232026 0.37019814 0.3933946  0.36160156
 0.38716453 0.3725434  0.37104575 0.39117672 0.40483262 0.39603542
 0.38212679 0.38196762 0.37476249 0.37426753 0.41594728 0.38796206
 0.40770408 0.39252184 0.38849034 0.36099026 0.37834437 0.38278181
 0.38850081 0.37195774 0.37349359 0.36257168 0.41931662 0.39102677]
[ 1 28 22 42 35 54 32 50  9 30 13 58 18 20  8 19 33 46  4 21 14 29 15 51
 37 57 26 61 68 70 39 56 43 62 66 71 47 45  7 55 65 72 27 60 16 53 67 69
 11 12  2 41 34 63  5 31 17 44 49 64 40 36 24 23 10 52  6 25  3 38 48 59]
shww_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(10,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.68281639 -0.69762456 -0.68280451 -0.70586123 -0.68891344 -0.7068779
 -0.68986397 -0.71248261 -0.69303622 -0.71195949 -0.69750772 -0.75219001
 -0.68180063 -0.70271972 -0.6867867  -0.6995758  -0.71528272 -0.71578413
 -0.68944589 -0.71062853 -0.68507657 -0.70185242 -0.67907352 -0.71943859
 -0.6957618  -0.73867505 -0.70661053 -0.74581637 -0.75660532 -0.78820143
 -0.69581877 -0.72098792 -0.70658586 -0.76405558 -0.72662023 -0.80681046
 -0.70622601 -0.73564311 -0.70499835 -0.73172643 -0.75219972 -0.77289058
 -0.68591191 -0.73664233 -0.68301808 -0.73782569 -0.73453567 -0.8370514
 -0.69079045 -0.69907373 -0.69061538 -0.70977447 -0.70081468 -0.73881363
 -0.68004487 -0.71097185 -0.68439594 -0.70582959 -0.70237116 -0.74771717
 -0.70011991 -0.70705354 -0.68394831 -0.70479006 -0.69816607 -0.73953386
 -0.68533317 -0.70276377 -0.68339035 -0.70295039 -0.69095782 -0.74451987]
[0.31144983 0.29957753 0.31976613 0.31429812 0.31392137 0.31436773
 0.31724989 0.30966383 0.32299122 0.30458761 0.33514169 0.39200561
 0.31730762 0.2974374  0.31328637 0.31748504 0.33826942 0.30694026
 0.31712694 0.31254809 0.31104043 0.3128804  0.32417601 0.32799655
 0.31303705 0.28988348 0.29905718 0.29541858 0.32292489 0.29410233
 0.32119574 0.30450488 0.3235977  0.32252399 0.32396797 0.34770966
 0.3332358  0.30804361 0.32391897 0.30667412 0.32920501 0.29861969
 0.29739656 0.29746466 0.30867291 0.30404695 0.30881296 0.28878075
 0.32383944 0.31527872 0.31228635 0.29536186 0.30944082 0.30619103
 0.31460508 0.30043443 0.30340801 0.29766547 0.31904933 0.30646393
 0.32823254 0.31025709 0.31143016 0.2938921  0.32064332 0.31048885
 0.31492912 0.29326677 0.32162471 0.31851667 0.31038207 0.31892904]
[ 5 24  4 38 14 42 16 48 20 47 23 65  3 32 13 27 49 50 15 45 10 30  1 51
 21 59 41 63 67 70 22 52 40 68 53 71 39 56 36 54 66 69 12 57  6 58 55 72
 18 26 17 44 29 60  2 46  9 37 31 64 28 43  8 35 25 61 11 33  7 34 19 62]
mdts_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(10,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.09117477 -0.09119369 -0.09486641 -0.09166647 -0.08959701 -0.09017392
 -0.09397816 -0.09273235 -0.09452041 -0.08951905 -0.09036289 -0.09394762
 -0.09425357 -0.09377679 -0.09405692 -0.09154136 -0.09387891 -0.0893689
 -0.09533965 -0.09219746 -0.09354936 -0.09256298 -0.08850238 -0.09025199
 -0.09383389 -0.09196758 -0.09664532 -0.09040524 -0.09922634 -0.09954265
 -0.09426544 -0.09168716 -0.09772515 -0.09074501 -0.10135531 -0.09951284
 -0.09544963 -0.09347877 -0.0946134  -0.09092809 -0.09557813 -0.09542883
 -0.09359817 -0.09067594 -0.09615988 -0.09090315 -0.10218137 -0.09851748
 -0.09300095 -0.0893246  -0.09436408 -0.09050415 -0.09748888 -0.09918711
 -0.09342917 -0.08892693 -0.09404766 -0.09162222 -0.09474489 -0.09639051
 -0.0922447  -0.09056587 -0.09532476 -0.09056409 -0.09807036 -0.0932205
 -0.09307695 -0.09035527 -0.09343544 -0.09061398 -0.09679045 -0.0984756 ]
[0.05242003 0.04225438 0.05370895 0.04414962 0.05305774 0.05239797
 0.05344304 0.04403543 0.05336337 0.04214349 0.05199743 0.05282789
 0.0523964  0.0454352  0.05395007 0.04802338 0.05277094 0.04790675
 0.05218406 0.04403392 0.0503222  0.04489414 0.05406891 0.04847227
 0.05284169 0.04404798 0.05032375 0.04142595 0.05270595 0.04108699
 0.05020044 0.04508751 0.05184318 0.04448396 0.05325274 0.0399412
 0.0517589  0.04594588 0.0496619  0.04332233 0.04916936 0.0451699
 0.05186104 0.04221011 0.05203227 0.04528701 0.05040407 0.04204033
 0.0526431  0.04396331 0.05252142 0.04408524 0.05285762 0.04159766
 0.05290112 0.04410312 0.05186761 0.04378612 0.05142883 0.04332945
 0.05193097 0.04428601 0.0514296  0.0442902  0.05469381 0.04275717
 0.05366337 0.04750079 0.05086246 0.0428055  0.05041473 0.04482122]
[20 21 52 24  6  7 43 30 49  5 10 42 46 39 45 22 41  4 54 27 37 29  1  8
 40 26 60 11 68 70 47 25 63 17 71 69 56 36 50 19 57 55 38 16 58 18 72 66
 31  3 48 12 62 67 34  2 44 23 51 59 28 14 53 13 64 33 32  9 35 15 61 65]
mdts_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(10,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.10381069 -0.10216882 -0.10339066 -0.1017977  -0.10281819 -0.09405859
 -0.10499895 -0.10676008 -0.10184841 -0.10812138 -0.10290263 -0.09682002
 -0.10427736 -0.10855347 -0.10380121 -0.10379128 -0.10181229 -0.09783501
 -0.10386413 -0.10534026 -0.10919894 -0.10406057 -0.10135049 -0.10032908
 -0.10469422 -0.10094733 -0.10479669 -0.09924928 -0.11008439 -0.10967079
 -0.10455492 -0.09986617 -0.10770102 -0.10116583 -0.11102873 -0.10956284
 -0.10444232 -0.10045836 -0.10371911 -0.09879304 -0.11182343 -0.1059277
 -0.10398123 -0.10248302 -0.10464949 -0.10197611 -0.11101025 -0.10772563
 -0.10427981 -0.10066388 -0.10560011 -0.10266266 -0.1117719  -0.10321385
 -0.1043295  -0.10310666 -0.10648922 -0.10304718 -0.10944048 -0.10547228
 -0.10332081 -0.09854937 -0.10674551 -0.09966872 -0.10544674 -0.10312046
 -0.10471859 -0.099138   -0.10361948 -0.10173352 -0.10579516 -0.10795427]
[0.04531972 0.04006801 0.04711811 0.03769151 0.0447037  0.04623575
 0.04164118 0.0417989  0.04430729 0.041546   0.04494627 0.04477667
 0.04508489 0.04302052 0.04451492 0.03904901 0.04968043 0.0413808
 0.04710928 0.03909411 0.04491483 0.04362181 0.04773498 0.04808597
 0.04405311 0.03961888 0.0471201  0.03792249 0.04370974 0.04007322
 0.0436587  0.03847495 0.04421346 0.03913727 0.0431428  0.03638222
 0.04445593 0.04058114 0.04621128 0.03970412 0.04657608 0.03995709
 0.04675298 0.03874831 0.04802367 0.03959862 0.0442478  0.03686076
 0.04694896 0.0397307  0.04738136 0.03861021 0.04288041 0.03583869
 0.04578142 0.03847252 0.04430564 0.03789999 0.04501678 0.03616053
 0.04788083 0.04054948 0.04509956 0.03904952 0.04550413 0.03696567
 0.04546869 0.0380166  0.04571444 0.03971098 0.04300997 0.03684115]
[36 21 31 17 24  1 49 58 19 62 25  2 40 63 35 34 18  3 37 50 64 39 15 10
 46 13 48  7 68 67 44  9 59 14 70 66 43 11 33  5 72 55 38 22 45 20 69 60
 41 12 53 23 71 29 42 27 56 26 65 52 30  4 57  8 51 28 47  6 32 16 54 61]
shts_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(10,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.55237809 -0.57561815 -0.55193661 -0.58002453 -0.55491575 -0.57815308
 -0.54726113 -0.57634377 -0.54769985 -0.57631865 -0.54764509 -0.58949677
 -0.55959239 -0.56955069 -0.55340306 -0.58167286 -0.5550098  -0.57888045
 -0.54558455 -0.57560703 -0.54594314 -0.57525466 -0.56015424 -0.57420054
 -0.5673653  -0.61094746 -0.5733824  -0.61705023 -0.61700161 -0.66192427
 -0.5693138  -0.59918389 -0.56889765 -0.60734459 -0.59127673 -0.65928148
 -0.58345558 -0.60254568 -0.57992952 -0.60629097 -0.59618128 -0.64904273
 -0.57899539 -0.59787107 -0.57007331 -0.60250169 -0.58556304 -0.66652506
 -0.55602023 -0.57136406 -0.56671957 -0.57888366 -0.5921228  -0.60751062
 -0.55638758 -0.5826384  -0.55423937 -0.583733   -0.58543903 -0.62590142
 -0.56177073 -0.5726232  -0.56708986 -0.57672679 -0.57839339 -0.611682
 -0.55861891 -0.56638657 -0.55664991 -0.58519314 -0.57320075 -0.59759478]
[0.14847718 0.13519432 0.14836523 0.13831642 0.14404817 0.14279026
 0.14044343 0.12971858 0.14798063 0.13757703 0.15381063 0.16232792
 0.15002833 0.12680687 0.14680202 0.12719867 0.16393386 0.12742925
 0.14439203 0.12626767 0.14712399 0.13132697 0.14815305 0.13510847
 0.1420265  0.13595366 0.14535447 0.13826732 0.18975855 0.14374715
 0.15211832 0.12415154 0.15969988 0.14015488 0.16458245 0.14971764
 0.15450819 0.13469276 0.15567604 0.13871533 0.17659043 0.15720165
 0.15073181 0.1372672  0.14932468 0.13667033 0.17625576 0.14697305
 0.14689942 0.14720737 0.14533471 0.14025919 0.16589451 0.14977479
 0.14233849 0.14456802 0.14342407 0.14636586 0.15544218 0.1639046
 0.15581261 0.15290488 0.14892077 0.15486705 0.16350815 0.15384645
 0.14767524 0.14552202 0.14177905 0.13823391 0.15975508 0.14440195]
[ 7 34  6 44 10 38  3 36  5 35  4 52 16 25  8 45 11 40  1 33  2 32 17 31
 22 64 30 67 66 71 24 58 23 62 53 70 47 60 43 61 55 69 42 57 26 59 51 72
 12 27 20 41 54 63 13 46  9 48 50 68 18 28 21 37 39 65 15 19 14 49 29 56]
shts_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(10,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.48841897 -0.50502262 -0.48386097 -0.50798893 -0.49977588 -0.50470034
 -0.49288974 -0.51562782 -0.4852921  -0.50741061 -0.49091278 -0.50621923
 -0.48762764 -0.50780802 -0.49325611 -0.51649828 -0.48932848 -0.5058382
 -0.48429979 -0.50666921 -0.49147833 -0.50569667 -0.48861944 -0.51429632
 -0.5093152  -0.52177573 -0.51382935 -0.5412742  -0.5398033  -0.58375286
 -0.51199497 -0.52548145 -0.51149975 -0.54030971 -0.52735757 -0.59331478
 -0.51324087 -0.54713488 -0.51266661 -0.54327287 -0.53688807 -0.56784687
 -0.50649189 -0.52885571 -0.51147479 -0.54442447 -0.53052981 -0.57742074
 -0.49898521 -0.50358956 -0.49355004 -0.51455757 -0.52528681 -0.5522441
 -0.49135087 -0.51554009 -0.50260304 -0.51916266 -0.52085659 -0.5364116
 -0.49588161 -0.51128406 -0.49513484 -0.50678527 -0.5294713  -0.55104971
 -0.49893679 -0.50770722 -0.48896783 -0.52099199 -0.50163946 -0.54251978]
[0.11256382 0.10226679 0.10969922 0.09603976 0.116236   0.1166753
 0.12502397 0.08991191 0.10914378 0.09685609 0.12300248 0.12570599
 0.10454302 0.10446172 0.11164222 0.1091899  0.11712227 0.10196669
 0.10982502 0.10364467 0.11112072 0.10284752 0.12127978 0.1211652
 0.11369987 0.09955633 0.11276438 0.10538341 0.14558409 0.12112105
 0.1161193  0.09977272 0.11480454 0.10130926 0.1243506  0.11657933
 0.11552353 0.10136219 0.11993119 0.09504078 0.12837605 0.12117499
 0.11774394 0.10416873 0.11106489 0.09129615 0.12772467 0.10540535
 0.11410039 0.11108313 0.1083684  0.10591856 0.12093571 0.11423369
 0.10441813 0.10968303 0.11492347 0.10263189 0.11789856 0.1051421
 0.11435294 0.10816166 0.10749624 0.10719115 0.13125123 0.10787594
 0.10891421 0.10962922 0.1059135  0.10898658 0.11777803 0.09735014]
[ 5 24  1 34 19 23 12 46  3 31  9 27  4 33 13 47  8 26  2 29 11 25  6 43
 35 51 42 62 60 71 39 53 38 61 54 72 41 66 40 64 59 69 28 55 37 65 57 70
 18 22 14 44 52 68 10 45 21 48 49 58 16 36 15 30 56 67 17 32  7 50 20 63]

*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 13087673)                   *
*                                                                           *
*****************************************************************************

Job ID: 13087673
Cluster: finisterrae3
User/Group: curso342/ulc
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 32
CPU Utilized: 3-09:41:22
CPU Efficiency: 91.95% of 3-16:50:40 core-walltime
Job Wall-clock time: 02:46:35
Memory Utilized: 15.52 GB
Memory Efficiency: 97.02% of 16.00 GB

*****************************************************************************

