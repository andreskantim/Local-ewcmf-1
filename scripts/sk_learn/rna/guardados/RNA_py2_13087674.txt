slurmstepd: info: Setting TMPDIR to /scratch/13087674. Previous errors about TMPDIR can be discarded
dwi_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(25,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.47087025 -0.48054341 -0.47189443 -0.4918563  -0.48028179 -0.48002408
 -0.47327919 -0.48556597 -0.47084007 -0.49693912 -0.46999262 -0.48873474
 -0.46997816 -0.47869102 -0.47919382 -0.47996205 -0.46613098 -0.49066513
 -0.47035024 -0.48366603 -0.47448505 -0.488551   -0.47009852 -0.48975955
 -0.47182212 -0.49204224 -0.47666115 -0.49742621 -0.49718841 -0.51489332
 -0.47657422 -0.49481001 -0.48316379 -0.51268818 -0.49332961 -0.51355558
 -0.47029174 -0.48956571 -0.4724116  -0.49600962 -0.48548417 -0.51443389
 -0.47583225 -0.49772328 -0.47903517 -0.51201962 -0.48681128 -0.51686715
 -0.46561874 -0.47613728 -0.47160425 -0.48274879 -0.48302371 -0.49843811
 -0.47048085 -0.489059   -0.47451815 -0.49878026 -0.48316769 -0.50441305
 -0.46624231 -0.47068479 -0.46429391 -0.48035785 -0.48123587 -0.50191212
 -0.46955028 -0.47765641 -0.47292115 -0.48680235 -0.48720503 -0.51006853]
[0.0583033  0.06400479 0.05456164 0.06940141 0.05481177 0.0645411
 0.05415022 0.06498158 0.06029377 0.07261397 0.05232511 0.05382865
 0.05573425 0.06974759 0.04804587 0.05916216 0.06137686 0.05434324
 0.05352329 0.06112966 0.05626539 0.05740326 0.05876437 0.06293182
 0.05727299 0.05981452 0.04758473 0.05579645 0.04630044 0.06960938
 0.05300481 0.05606871 0.0567856  0.05643173 0.04841967 0.06377396
 0.05573689 0.0642995  0.0543427  0.05834441 0.05974969 0.06117005
 0.05511755 0.06569379 0.05604431 0.05265253 0.05163403 0.04896434
 0.05621134 0.06437931 0.05013689 0.0595132  0.05391498 0.06150389
 0.05558933 0.06384709 0.05528143 0.06060825 0.05233951 0.05823475
 0.05550274 0.06191503 0.05551729 0.06027831 0.05335176 0.05836974
 0.05543582 0.06197357 0.05357761 0.06064449 0.05861115 0.06224657]
[14 35 17 53 33 32 20 43 13 58  7 48  6 28 30 31  3 52 10 41 21 47  8 51
 16 54 26 60 59 71 25 56 39 68 55 69  9 50 18 57 42 70 23 61 29 67 45 72
  2 24 15 37 38 62 11 49 22 63 40 65  4 12  1 34 36 64  5 27 19 44 46 66]
dwi_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(25,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.43089324 -0.43169406 -0.42500498 -0.43206643 -0.41795474 -0.42589911
 -0.42719038 -0.43921732 -0.43055409 -0.43811967 -0.43005722 -0.43607053
 -0.42768016 -0.430722   -0.42976779 -0.42185059 -0.42725137 -0.43447429
 -0.42468369 -0.4375358  -0.42684067 -0.4338895  -0.42409295 -0.43450107
 -0.43153094 -0.44323758 -0.43242708 -0.44506247 -0.44100859 -0.45869042
 -0.42984007 -0.44801203 -0.43888834 -0.45939826 -0.44159081 -0.46346559
 -0.43249587 -0.43518007 -0.4311607  -0.4396946  -0.44871833 -0.45227622
 -0.42876673 -0.44069108 -0.43154822 -0.45471721 -0.45162401 -0.46556697
 -0.41945326 -0.41771775 -0.43057426 -0.43229626 -0.44503775 -0.4485095
 -0.42674319 -0.43262501 -0.43395346 -0.44780502 -0.43361508 -0.45446064
 -0.42284867 -0.41492571 -0.42384142 -0.42623891 -0.43147583 -0.44553905
 -0.42352929 -0.43255228 -0.43269525 -0.44177001 -0.44345866 -0.45529589]
[0.04115684 0.04007077 0.03328655 0.04287863 0.0306963  0.04833927
 0.0454861  0.04089577 0.03565575 0.03306179 0.04608665 0.04641736
 0.04047398 0.03997971 0.04229846 0.03725709 0.03463039 0.03090629
 0.03679973 0.03818433 0.0373681  0.03588662 0.04569871 0.03469985
 0.03169625 0.0347715  0.03536012 0.03399947 0.04143782 0.04914689
 0.03651957 0.03821075 0.03742784 0.03480961 0.03149403 0.03419655
 0.03599247 0.03483133 0.03217154 0.03540133 0.03782481 0.04015929
 0.03668275 0.03920037 0.03336391 0.03460703 0.04141829 0.02841868
 0.0359717  0.03635085 0.0368818  0.03947937 0.04355478 0.05264064
 0.03708655 0.04272367 0.0379244  0.03727959 0.03500551 0.03461748
 0.03679697 0.03589725 0.03602974 0.03677855 0.03780707 0.03463123
 0.03235146 0.03646379 0.03666134 0.03210929 0.0383968  0.03342612]
[26 31 11 32  3 12 16 49 23 47 22 45 18 25 20  5 17 42 10 46 15 40  9 43
 29 55 34 58 52 69 21 61 48 70 53 71 35 44 27 50 63 65 19 51 30 67 64 72
  4  2 24 33 57 62 14 37 41 60 39 66  6  1  8 13 28 59  7 36 38 54 56 68]
wind_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(25,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-2.38393567 -2.40361562 -2.34868101 -2.41609572 -2.32381662 -2.48044027
 -2.36728139 -2.43738128 -2.33649392 -2.44271356 -2.37011871 -2.50567512
 -2.40626834 -2.41920637 -2.36564333 -2.42060658 -2.36879976 -2.43537898
 -2.34694981 -2.43514468 -2.36502657 -2.41826575 -2.35581595 -2.46482847
 -2.34070223 -2.43152573 -2.36438645 -2.50493527 -2.45680048 -2.62965231
 -2.38812565 -2.50046046 -2.3842702  -2.51911762 -2.44592072 -2.64412777
 -2.36202252 -2.41550737 -2.38371582 -2.44939004 -2.46598514 -2.6374832
 -2.37250169 -2.44843616 -2.39722807 -2.51195104 -2.48041969 -2.67771308
 -2.3423486  -2.40797826 -2.33349213 -2.43071693 -2.44449882 -2.54711139
 -2.3298503  -2.42422861 -2.33445414 -2.44858208 -2.49934126 -2.59646262
 -2.36000436 -2.41910574 -2.33596425 -2.40325223 -2.41527495 -2.57871257
 -2.34572889 -2.42874883 -2.34647678 -2.42611223 -2.44657121 -2.55402683]
[0.39430695 0.3682711  0.39130405 0.403666   0.40683841 0.3696129
 0.43021844 0.35460582 0.4011477  0.34663851 0.38421891 0.38928701
 0.38565562 0.37687821 0.39095623 0.34994532 0.40164772 0.38497495
 0.39586276 0.38736167 0.42313504 0.38284742 0.43454776 0.34146182
 0.42800543 0.3285913  0.4176003  0.38156897 0.45428324 0.32603261
 0.43095461 0.32376564 0.40774076 0.32821534 0.42908801 0.35116274
 0.43108455 0.38694902 0.411828   0.3737369  0.39129951 0.35928048
 0.40518508 0.34817118 0.42282342 0.35123753 0.39976877 0.33991369
 0.44466421 0.37889892 0.41361593 0.36664404 0.46386555 0.31318463
 0.41324414 0.35182605 0.41216783 0.3499983  0.43331831 0.36168597
 0.46683051 0.38342419 0.42464537 0.37328527 0.42665469 0.34001598
 0.4135684  0.37007196 0.43239708 0.38293077 0.40917453 0.34244012]
[24 29 12 34  1 58 19 46  6 47 21 62 30 37 18 38 20 45 11 44 17 35 13 55
  7 43 16 61 54 69 26 60 25 64 49 71 15 33 23 53 56 70 22 51 27 63 57 72
  8 31  3 42 48 65  2 39  4 52 59 68 14 36  5 28 32 67  9 41 10 40 50 66]
wind_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(25,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-2.04819377 -2.08058119 -2.06157253 -2.10713056 -2.06279042 -2.11747442
 -2.02942323 -2.07019032 -2.03387733 -2.11135065 -2.03404614 -2.16444869
 -2.0604001  -2.08523547 -2.06934301 -2.08894219 -2.08116245 -2.14586116
 -2.05073668 -2.06507597 -2.06275975 -2.10218193 -2.07012836 -2.18439944
 -2.06699345 -2.12178242 -2.07461989 -2.1728963  -2.14477657 -2.30995059
 -2.08765112 -2.18106897 -2.10921462 -2.21159649 -2.15774846 -2.30322308
 -2.06385213 -2.13146509 -2.09275432 -2.17442553 -2.15209319 -2.31438669
 -2.07134847 -2.15993955 -2.0998588  -2.19506678 -2.15437712 -2.34560952
 -2.04208093 -2.08125405 -2.02830812 -2.0773363  -2.12201025 -2.23216999
 -2.03017983 -2.08796912 -2.04390982 -2.11049541 -2.13467191 -2.21122779
 -2.04372708 -2.08571733 -2.04053325 -2.08078925 -2.08960097 -2.16809935
 -2.03098881 -2.07462798 -2.049906   -2.09058594 -2.12985747 -2.18825052]
[0.41183637 0.40499421 0.3963146  0.42085906 0.45258993 0.34811044
 0.40333945 0.38556693 0.40708934 0.40445666 0.44396517 0.35884141
 0.42294931 0.40819772 0.41364488 0.39707689 0.43897941 0.35080569
 0.42595693 0.39955967 0.44386928 0.41656602 0.39906668 0.39891322
 0.44475732 0.37293129 0.43801478 0.38790993 0.44532992 0.34578586
 0.47645419 0.36656474 0.4568394  0.3999754  0.43686752 0.3961636
 0.44950865 0.39142211 0.45029459 0.39656603 0.44180331 0.4226296
 0.44024822 0.38625626 0.44120258 0.3774903  0.42430727 0.41963333
 0.45750894 0.41245166 0.43081492 0.3894567  0.43492364 0.41436671
 0.4341518  0.39407024 0.43697643 0.36359432 0.41705867 0.34350424
 0.46668412 0.4206721  0.43935967 0.39248999 0.42865956 0.37892455
 0.43217253 0.39724008 0.45262323 0.39145672 0.4424403  0.38166312]
[11 28 15 42 17 46  2 23  5 45  6 58 14 32 21 36 30 53 13 19 16 41 22 63
 20 47 25 60 52 70 34 62 43 67 56 69 18 50 39 61 54 71 24 57 40 65 55 72
  8 31  1 27 48 68  3 35 10 44 51 66  9 33  7 29 37 59  4 26 12 38 49 64]
shww_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(25,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.92353572 -0.92980353 -0.92074386 -0.96171504 -0.93450076 -0.93925264
 -0.92109809 -0.96853377 -0.92902636 -0.96134733 -0.9097542  -0.9808211
 -0.91585054 -0.92932977 -0.91926958 -0.93325178 -0.93171688 -0.96570096
 -0.92145992 -0.94368447 -0.9052604  -0.96894013 -0.89814538 -0.95697794
 -0.92906469 -0.9632765  -0.93940494 -1.00442354 -0.99341176 -1.03844788
 -0.95085265 -1.00456583 -0.96560217 -1.03118564 -0.98604464 -1.0850436
 -0.9421338  -0.97143413 -0.93889422 -0.98602506 -0.98419435 -1.06126705
 -0.92977048 -0.97655739 -0.95422191 -1.01845014 -0.9892499  -1.05533916
 -0.91101554 -0.92583839 -0.91387912 -0.96338777 -0.98527141 -1.05988078
 -0.91588256 -0.95117328 -0.91480816 -0.98636429 -0.94913908 -1.05041052
 -0.92141794 -0.92286178 -0.920306   -0.94130846 -0.9519949  -1.0441021
 -0.91222348 -0.93622913 -0.92351341 -0.96760303 -0.9468125  -1.03194676]
[0.38743375 0.36390711 0.37026143 0.37185643 0.42339228 0.40512376
 0.37660689 0.3748115  0.38798383 0.37340568 0.39090303 0.43308618
 0.38850341 0.36681928 0.3749593  0.37539519 0.40226903 0.40918557
 0.37229906 0.37236782 0.3550446  0.36305493 0.38482867 0.39798026
 0.37982253 0.36033381 0.3882765  0.36168099 0.39011149 0.32925407
 0.39144834 0.35958019 0.40585133 0.35821564 0.38140308 0.37446869
 0.39111592 0.3766985  0.36890549 0.3490354  0.40392448 0.33645057
 0.36815047 0.34625012 0.40997219 0.3597759  0.39408688 0.34254331
 0.38418422 0.37426265 0.38977594 0.38332353 0.38544604 0.35671819
 0.38324964 0.39250073 0.37990103 0.38640929 0.38192122 0.34402792
 0.39196044 0.3783167  0.39172988 0.36686548 0.39333257 0.36862918
 0.37988425 0.37733525 0.38053075 0.35573081 0.35756584 0.34461048]
[18 24 12 43 27 30 13 49 20 42  3 53  8 22 10 26 25 47 15 34  2 50  1 41
 21 44 31 61 60 66 37 62 46 64 57 72 33 51 29 56 54 71 23 52 40 63 59 69
  4 19  6 45 55 70  9 38  7 58 36 68 14 16 11 32 39 67  5 28 17 48 35 65]
shww_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(25,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.68779196 -0.70461933 -0.69876095 -0.72844192 -0.69149373 -0.71148878
 -0.68626784 -0.75223764 -0.7106247  -0.75178702 -0.678221   -0.7212452
 -0.69042016 -0.7103507  -0.68705892 -0.71214246 -0.70247429 -0.7423077
 -0.68858005 -0.71350235 -0.69224064 -0.74743698 -0.70118864 -0.75704918
 -0.71927357 -0.7601721  -0.71050792 -0.77565824 -0.76935176 -0.82987203
 -0.71987964 -0.78118659 -0.7207614  -0.79076862 -0.76651707 -0.81002088
 -0.71779016 -0.73306132 -0.71482306 -0.75519942 -0.78115131 -0.81997074
 -0.71118822 -0.75176291 -0.72527425 -0.78304065 -0.77069272 -0.81876843
 -0.69899207 -0.72359562 -0.70472269 -0.72703295 -0.7289977  -0.78564046
 -0.69930284 -0.73695126 -0.71254493 -0.75435371 -0.75287769 -0.81809778
 -0.69688835 -0.70626871 -0.69650566 -0.71471145 -0.71084772 -0.77679846
 -0.69820925 -0.72053719 -0.70496074 -0.73500899 -0.73287479 -0.79106759]
[0.31631111 0.30143443 0.33139121 0.29975995 0.30783971 0.34929013
 0.30906211 0.33083877 0.32367612 0.33359636 0.32095283 0.35998608
 0.30835492 0.31137551 0.30410524 0.30942034 0.33155797 0.3508785
 0.3198061  0.31380333 0.31127255 0.30175974 0.33432045 0.37672124
 0.30895648 0.30633668 0.31720791 0.30567493 0.31089193 0.28500642
 0.31555262 0.29609883 0.30867257 0.31154645 0.34850328 0.29206865
 0.33422736 0.29969281 0.3278606  0.30945842 0.327767   0.29935829
 0.31367368 0.30447326 0.3353692  0.29933447 0.34254756 0.26874625
 0.316696   0.3055371  0.31652727 0.30421706 0.32611217 0.29263129
 0.3262845  0.31122518 0.33002542 0.29826816 0.31762211 0.29040196
 0.31267666 0.30947424 0.31168802 0.29482025 0.30910107 0.28442998
 0.31197015 0.30269826 0.32080898 0.30344961 0.32380072 0.28625716]
[ 4 17 12 41  7 26  2 51 23 50  1 37  6 21  3 27 16 47  5 29  8 48 15 55
 33 56 22 60 58 72 34 63 36 66 57 68 32 44 31 54 62 71 25 49 39 64 59 70
 13 38 18 40 42 65 14 46 28 53 52 69 10 20  9 30 24 61 11 35 19 45 43 67]
mdts_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(25,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.0981694  -0.09599935 -0.10257928 -0.09638091 -0.09171962 -0.09370859
 -0.09772162 -0.09551203 -0.09836869 -0.09861926 -0.08970319 -0.09358908
 -0.09634342 -0.09562235 -0.1029614  -0.0963448  -0.09089321 -0.08915711
 -0.09872895 -0.09794894 -0.09858875 -0.09854946 -0.09311495 -0.09175749
 -0.09583345 -0.09359321 -0.09847816 -0.09419477 -0.1121215  -0.10788226
 -0.09778186 -0.09535133 -0.09949942 -0.09854668 -0.11226877 -0.10954454
 -0.09644869 -0.09396376 -0.09804852 -0.09271059 -0.10834816 -0.10407332
 -0.09642765 -0.09679204 -0.09894546 -0.0979432  -0.10666428 -0.10841642
 -0.0954413  -0.0922212  -0.09937158 -0.09368218 -0.10202474 -0.10181629
 -0.09678238 -0.09424829 -0.09948834 -0.09683396 -0.09858301 -0.10377275
 -0.09576549 -0.09114989 -0.09672563 -0.09352859 -0.10341254 -0.10369224
 -0.09750034 -0.09261442 -0.09881157 -0.09612338 -0.10163688 -0.10249741]
[0.0484892  0.04625957 0.05150452 0.04075443 0.05196345 0.04960729
 0.05213373 0.04050287 0.0484975  0.04277858 0.0553724  0.05326098
 0.05018493 0.04030549 0.04871609 0.04394659 0.05001102 0.04917654
 0.05474279 0.04618385 0.04938589 0.04275217 0.05458988 0.0507121
 0.04764479 0.04027501 0.05376988 0.03918403 0.05136849 0.04157321
 0.05048106 0.04390725 0.05166626 0.04210302 0.05062269 0.04304597
 0.05076945 0.04326407 0.04696584 0.0386867  0.04543222 0.04214729
 0.04685324 0.04071813 0.04747558 0.03938339 0.04923926 0.04135816
 0.05132822 0.0456711  0.05292023 0.04216068 0.05062691 0.04027467
 0.05265265 0.04511677 0.04755231 0.04319783 0.05025149 0.04108911
 0.05454295 0.04519206 0.04969723 0.0429583  0.04939807 0.04010472
 0.0523988  0.04304728 0.05071616 0.04361467 0.0493749  0.04204315]
[42 25 60 29  5 15 37 21 43 49  2 12 27 22 61 28  3  1 50 40 48 46 10  6
 24 13 44 17 71 67 38 19 55 45 72 70 31 16 41  9 68 65 30 34 52 39 66 69
 20  7 53 14 58 57 33 18 54 35 47 64 23  4 32 11 62 63 36  8 51 26 56 59]
mdts_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(25,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.11099291 -0.10740399 -0.10971265 -0.11404368 -0.11215627 -0.10035311
 -0.10929849 -0.10773364 -0.10672924 -0.11326747 -0.10349551 -0.09870474
 -0.11321641 -0.10510961 -0.11203499 -0.10647274 -0.10161576 -0.10125911
 -0.10938252 -0.1070533  -0.11382241 -0.11119652 -0.10295301 -0.09829378
 -0.10763062 -0.10865041 -0.11027961 -0.10990906 -0.12041229 -0.11804053
 -0.10818036 -0.1095425  -0.11574555 -0.11375303 -0.11981764 -0.11626319
 -0.10950672 -0.10775844 -0.10928651 -0.10833886 -0.11886695 -0.11535192
 -0.10770268 -0.11039915 -0.11019546 -0.116175   -0.12021316 -0.12223614
 -0.1082521  -0.10418349 -0.10970215 -0.10826563 -0.11476208 -0.11118103
 -0.11003726 -0.1082055  -0.11199124 -0.11068172 -0.1131076  -0.11632523
 -0.10801807 -0.10088256 -0.10763421 -0.10646565 -0.11540107 -0.11510119
 -0.10576747 -0.10453337 -0.1091383  -0.11174606 -0.11916702 -0.11761183]
[0.04908673 0.0381478  0.04739651 0.04196739 0.03882948 0.05038854
 0.03834732 0.03788492 0.04525119 0.04049586 0.04427401 0.04387522
 0.04413412 0.03296957 0.0449616  0.03832792 0.04534943 0.04411679
 0.04472712 0.03690425 0.05044633 0.03761964 0.04610677 0.04937775
 0.04548233 0.0338874  0.04512577 0.03402998 0.04450489 0.03723908
 0.04526498 0.0365241  0.04636205 0.0354465  0.04408149 0.03106373
 0.0462712  0.03502267 0.04189929 0.03472396 0.0440712  0.03302284
 0.04319839 0.03729871 0.04398031 0.03570826 0.04055204 0.03765991
 0.04761526 0.04008063 0.04693609 0.03853264 0.04764317 0.03440221
 0.04740561 0.03590387 0.04629996 0.03641978 0.03831143 0.03786133
 0.04699001 0.03829659 0.04408952 0.03616141 0.04416467 0.03262609
 0.04498505 0.0370261  0.04468501 0.03613014 0.04522969 0.03595763]
[44 17 37 56 50  3 32 21 15 53  8  2 52 11 49 14  6  5 33 16 55 46  7  1
 18 29 41 38 71 66 24 35 61 54 69 63 34 22 31 28 67 59 20 42 40 62 70 72
 26  9 36 27 57 45 39 25 48 43 51 64 23  4 19 13 60 58 12 10 30 47 68 65]
shts_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(25,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.56923698 -0.57056379 -0.55710609 -0.57996377 -0.5437123  -0.6001571
 -0.56153817 -0.59131818 -0.5630327  -0.60232329 -0.56361871 -0.61949621
 -0.56473673 -0.58100324 -0.56964115 -0.58172462 -0.54725678 -0.58474226
 -0.55034863 -0.58286443 -0.55656897 -0.59272807 -0.55211449 -0.60683908
 -0.5821925  -0.60639732 -0.60077841 -0.62310184 -0.61156565 -0.65369336
 -0.5859034  -0.61978256 -0.59850766 -0.63752229 -0.6151631  -0.67316332
 -0.58925014 -0.60864755 -0.59143051 -0.6202012  -0.62156422 -0.67696845
 -0.58358295 -0.61316366 -0.58118862 -0.63947627 -0.61172266 -0.66082468
 -0.55487133 -0.57388343 -0.56362258 -0.58459312 -0.58221609 -0.63461623
 -0.56078958 -0.58585688 -0.56290427 -0.60955012 -0.59749597 -0.6355261
 -0.55936749 -0.56828501 -0.55780324 -0.58335825 -0.58528223 -0.62441263
 -0.55973032 -0.58272485 -0.56173214 -0.5928365  -0.58565619 -0.63465958]
[0.14862526 0.1348916  0.14404263 0.13530672 0.15006355 0.17560855
 0.14941452 0.12642046 0.13399629 0.15280212 0.15273464 0.19053123
 0.14537052 0.13092672 0.15625935 0.14647574 0.13130196 0.14018918
 0.1429157  0.1372191  0.14448862 0.12808979 0.15436336 0.18725754
 0.15450845 0.13680662 0.16802887 0.12969762 0.16117123 0.13676356
 0.15586721 0.13032382 0.15646143 0.13069633 0.15369331 0.13251344
 0.14121946 0.12126564 0.15412178 0.13346184 0.15024946 0.12675313
 0.15432366 0.14404667 0.15871522 0.13678145 0.15538625 0.11750256
 0.14424347 0.14541695 0.15264556 0.14082091 0.14559093 0.1453188
 0.13870284 0.14638348 0.14102428 0.1418229  0.15964455 0.13829506
 0.1468511  0.14508543 0.14346052 0.13812892 0.15234979 0.14128354
 0.14494028 0.14392021 0.14797125 0.14032019 0.14089119 0.1511732 ]
[20 22  7 24  1 47 12 41 15 49 16 58 18 25 21 27  2 35  3 31  6 43  4 51
 28 50 48 62 54 69 39 59 46 67 57 71 40 52 42 60 61 72 33 56 26 68 55 70
  5 23 17 34 29 64 11 38 14 53 45 66  9 19  8 32 36 63 10 30 13 44 37 65]
shts_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(25,)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.48838057 -0.5125551  -0.49246076 -0.50571153 -0.49354687 -0.50576488
 -0.49943569 -0.53478066 -0.50631793 -0.53043149 -0.48257734 -0.5194
 -0.49757421 -0.51481186 -0.49700223 -0.51356125 -0.48233179 -0.50781393
 -0.49301494 -0.52076875 -0.49131609 -0.52787982 -0.4995155  -0.51490288
 -0.52371188 -0.54495179 -0.52198403 -0.56186349 -0.56075879 -0.58568951
 -0.52692271 -0.55143564 -0.52874329 -0.55911763 -0.53300767 -0.59120478
 -0.52009447 -0.53848335 -0.52623921 -0.54490761 -0.53241345 -0.58981199
 -0.51809123 -0.53333366 -0.53125655 -0.56317483 -0.5450861  -0.59370857
 -0.50025341 -0.50930404 -0.50831907 -0.51935918 -0.52377521 -0.54609757
 -0.50373574 -0.51689096 -0.5068194  -0.54185828 -0.53833059 -0.57401505
 -0.50086695 -0.50276079 -0.50024225 -0.51574763 -0.52954242 -0.54916532
 -0.5003133  -0.51649052 -0.512277   -0.53114376 -0.52881129 -0.57148393]
[0.11166613 0.10048268 0.11230633 0.09489241 0.12509324 0.11358237
 0.11292794 0.09725993 0.12550023 0.10403361 0.11985081 0.15643357
 0.11328458 0.10071004 0.12371721 0.10441181 0.12101274 0.11469225
 0.11506035 0.09983373 0.11625731 0.10444285 0.12440568 0.11351707
 0.11735685 0.09688853 0.11892512 0.10262014 0.12371798 0.09387939
 0.12339655 0.10576428 0.11788442 0.09061389 0.10523579 0.09454447
 0.1239247  0.08546425 0.11497514 0.08246246 0.11405186 0.10546932
 0.12195156 0.10016739 0.11980509 0.09920019 0.11940171 0.09345179
 0.11692395 0.10148445 0.1134166  0.09526887 0.11147242 0.0955703
 0.11479075 0.10772597 0.11070412 0.09747498 0.11962201 0.10125882
 0.11312116 0.1077622  0.11284797 0.10589493 0.12466983 0.09578073
 0.11094454 0.10618316 0.12191543 0.10394625 0.12508905 0.09621816]
[ 3 26  5 18  7 19 10 53 20 47  2 35  9 28  8 27  1 22  6 37  4 43 11 29
 39 58 38 65 64 69 42 62 44 63 51 71 36 55 41 57 50 70 33 52 49 66 59 72
 13 24 23 34 40 60 17 32 21 56 54 68 15 16 12 30 46 61 14 31 25 48 45 67]

*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 13087674)                   *
*                                                                           *
*****************************************************************************

Job ID: 13087674
Cluster: finisterrae3
User/Group: curso342/ulc
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 32
CPU Utilized: 3-12:01:54
CPU Efficiency: 97.07% of 3-14:34:08 core-walltime
Job Wall-clock time: 02:42:19
Memory Utilized: 15.64 GB
Memory Efficiency: 97.74% of 16.00 GB

*****************************************************************************

