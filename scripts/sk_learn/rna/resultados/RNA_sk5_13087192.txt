slurmstepd: info: Setting TMPDIR to /scratch/13087192. Previous errors about TMPDIR can be discarded
dwi_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50, 10)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.50263931 -0.50904819 -0.49268002 -0.51216302 -0.49310856 -0.50573914
 -0.49107555 -0.49571926 -0.5055774  -0.51073643 -0.49601159 -0.50452424
 -0.51148278 -0.50855348 -0.48491443 -0.48729384 -0.50245942 -0.49023375
 -0.49341838 -0.51734637 -0.50013018 -0.50638658 -0.49239221 -0.49461952
 -0.49733753 -0.50447682 -0.49681344 -0.49508568 -0.50763642 -0.5132466
 -0.4830885  -0.49496134 -0.47363747 -0.47915937 -0.47822952 -0.49977436
 -0.47215973 -0.48111513 -0.49337112 -0.49739201 -0.47604786 -0.47863568
 -0.47734294 -0.49513328 -0.47338714 -0.48365255 -0.4686997  -0.49167594]
[0.05739555 0.07263104 0.05420385 0.07272506 0.05583213 0.05790505
 0.05703523 0.06094689 0.05166431 0.0698695  0.07146898 0.06208717
 0.05723164 0.06568133 0.05330928 0.066855   0.05138606 0.06560671
 0.05932241 0.06127614 0.05559631 0.0651718  0.05906736 0.05625843
 0.05735991 0.05470599 0.05206889 0.06637241 0.05810031 0.0588392
 0.05389471 0.06643582 0.06732298 0.05815545 0.06350445 0.06415052
 0.06427156 0.06238178 0.06552859 0.06646329 0.0575472  0.05934224
 0.06341354 0.06302288 0.0587302  0.05839433 0.05427429 0.07516183]
[35 43 19 46 20 39 16 27 38 44 28 37 45 42 13 14 34 15 22 48 33 40 18 23
 30 36 29 25 41 47 11 24  4  9  7 32  2 10 21 31  5  8  6 26  3 12  1 17]
dwi_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50, 10)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.4549876  -0.45453115 -0.44123166 -0.43580135 -0.45959331 -0.44712241
 -0.43335271 -0.45649894 -0.45193538 -0.45355779 -0.44283134 -0.44055585
 -0.445134   -0.4578131  -0.4273006  -0.43492318 -0.44750022 -0.45083262
 -0.45589284 -0.45574858 -0.45981284 -0.45798761 -0.44735674 -0.44968293
 -0.45377369 -0.45017586 -0.45747127 -0.45891129 -0.44949015 -0.45547842
 -0.44146528 -0.44902139 -0.42580725 -0.42333542 -0.44861589 -0.44457162
 -0.43124841 -0.43337191 -0.45369707 -0.44081044 -0.431738   -0.43126469
 -0.44031058 -0.4444566  -0.43429713 -0.44114986 -0.43634357 -0.44133898]
[0.0418967  0.03848885 0.04623783 0.04241239 0.0407723  0.03677288
 0.03687225 0.08806032 0.0370839  0.03499173 0.04044086 0.04109509
 0.03199597 0.04210777 0.04021578 0.04349982 0.04904911 0.03738828
 0.03723732 0.0324681  0.03879612 0.04152407 0.04628883 0.0435014
 0.03339363 0.03271882 0.03222722 0.03783223 0.03430189 0.0345439
 0.04854681 0.04154093 0.03377106 0.04097879 0.04510998 0.03566047
 0.03785417 0.04375343 0.04844153 0.03344204 0.04308573 0.03586242
 0.04861281 0.04702687 0.03491725 0.03446938 0.03899295 0.03161842]
[38 37 17 11 47 24  7 42 33 34 20 14 23 44  3 10 26 32 41 40 48 45 25 30
 36 31 43 46 29 39 19 28  2  1 27 22  4  8 35 15  6  5 13 21  9 16 12 18]
wind_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50, 10)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-2.47990777 -2.56069577 -2.51614696 -2.5175136  -2.49962757 -2.52727352
 -2.48167654 -2.47077975 -2.50240951 -2.56086773 -2.46785303 -2.53528554
 -2.49926033 -2.57012685 -2.46460105 -2.50940733 -2.99497859 -2.96713837
 -2.65826888 -2.66053563 -2.66662499 -2.76665979 -2.46405122 -2.57314756
 -2.93467525 -2.99924679 -2.60322273 -2.68072606 -2.63309028 -2.73850425
 -2.486307   -2.58763573 -2.73442598 -2.89985625 -2.58734356 -2.62582579
 -2.55239023 -2.6583581  -2.47672119 -2.5885974  -2.75329827 -2.75573571
 -2.59326023 -2.78644124 -2.5118182  -2.56456842 -2.52411979 -2.55390837]
[0.43374164 0.37716698 0.40695146 0.36171984 0.4003425  0.35817594
 0.36919562 0.40901948 0.38298065 0.368627   0.48535609 0.39920163
 0.34637991 0.34472403 0.35259174 0.34106934 0.40371425 0.38249143
 0.3939566  0.38969262 0.38877101 0.40962881 0.47654602 0.38349863
 0.44727209 0.41404565 0.40705545 0.39653605 0.52650002 0.40837474
 0.43992576 0.39219365 0.4100498  0.40821449 0.4340042  0.35166988
 0.3935856  0.41206056 0.3924339  0.32588028 0.45294995 0.40669001
 0.38252205 0.40924087 0.3936491  0.34726371 0.48731801 0.34409699]
[ 6 21 14 15 10 17  7  4 11 22  3 18  9 24  2 12 47 46 33 35 36 42  1 25
 45 48 30 37 32 39  8 27 38 44 26 31 19 34  5 28 40 41 29 43 13 23 16 20]
wind_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50, 10)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-2.12967817 -2.13179319 -2.17620656 -2.19395451 -2.18460014 -2.18195692
 -2.16737813 -2.15229047 -2.15779101 -2.23991458 -2.19259466 -2.23704027
 -2.1542866  -2.20261107 -2.14195963 -2.16246261 -2.51382751 -2.53972508
 -2.28205289 -2.25712967 -2.26788588 -2.41007008 -2.1789482  -2.28368189
 -2.44668447 -2.52676077 -2.23739125 -2.34252102 -2.34337628 -2.35613888
 -2.15663207 -2.22934039 -2.31130475 -2.3603948  -2.21866272 -2.27589825
 -2.15945237 -2.22275121 -2.15804347 -2.19798566 -2.28629988 -2.34522884
 -2.29319892 -2.29726015 -2.16892575 -2.23361332 -2.17862598 -2.2260578 ]
[0.42057189 0.40926653 0.42607039 0.41631628 0.4511418  0.39573287
 0.43451146 0.42650303 0.43104463 0.34068518 0.4478552  0.43448454
 0.40061512 0.42679698 0.37199303 0.40997931 0.55107882 0.43180841
 0.47217427 0.37397997 0.42767721 0.43176667 0.46484127 0.47247658
 0.47468629 0.42550258 0.40717392 0.35560032 0.47402746 0.44331518
 0.48863278 0.4207403  0.48485415 0.45047393 0.47245355 0.39085057
 0.4251419  0.43278341 0.40515476 0.39760578 0.42272661 0.42830708
 0.33999385 0.43316364 0.4377206  0.41932225 0.38888982 0.4046878 ]
[ 1  2 13 19 17 16 11  4  7 29 18 27  5 21  3 10 46 48 33 30 31 44 15 34
 45 47 28 39 40 42  6 25 38 43 22 32  9 23  8 20 35 41 36 37 12 26 14 24]
shww_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50, 10)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.97543422 -0.98278219 -0.97555418 -0.95928663 -0.97137916 -0.94001565
 -0.94676157 -0.98735163 -0.94844438 -0.98577288 -0.97617214 -0.9741886
 -0.95400435 -0.97204236 -0.94251871 -0.94914215 -1.05932914 -1.07286998
 -1.04666556 -1.0701296  -1.03260979 -1.04411761 -1.00456844 -1.08301067
 -1.07087726 -1.09845039 -1.07050883 -1.03773082 -1.05391295 -1.05324151
 -1.00085537 -1.04180663 -0.99018369 -1.00222013 -0.94636355 -0.97760977
 -0.95907433 -0.97427167 -0.98513365 -0.99569326 -0.996134   -0.97297696
 -0.95854814 -0.98391498 -0.97421868 -0.95708446 -0.96764453 -0.96692098]
[0.39318312 0.36151504 0.41600512 0.37406467 0.41751901 0.38398554
 0.42923637 0.39184986 0.37342509 0.42202914 0.39059839 0.39519637
 0.40969206 0.40933759 0.40161972 0.38097872 0.41632067 0.41314037
 0.43997134 0.36247574 0.4180624  0.40015678 0.41606684 0.35833183
 0.41090525 0.42549296 0.45133485 0.39529253 0.3916115  0.39596356
 0.42864524 0.38132379 0.444955   0.39562503 0.42505927 0.40229534
 0.41332242 0.43836038 0.41787027 0.40179705 0.43733373 0.42300496
 0.42344732 0.43136172 0.43451826 0.39499249 0.45163588 0.42777485]
[20 24 21 11 14  1  4 28  5 27 22 17  7 15  2  6 42 46 39 43 35 38 34 47
 45 48 44 36 41 40 32 37 29 33  3 23 10 19 26 30 31 16  9 25 18  8 13 12]
shww_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50, 10)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.74767389 -0.73619905 -0.72125493 -0.72684857 -0.70643678 -0.72136425
 -0.72060957 -0.7354414  -0.74080264 -0.72470558 -0.71680759 -0.73151802
 -0.7350526  -0.7303378  -0.73201672 -0.74101151 -0.78897563 -0.81855039
 -0.78358319 -0.77919716 -0.75794674 -0.7737772  -0.76149632 -0.79284667
 -0.80244072 -0.79840529 -0.78290288 -0.7897424  -0.78669412 -0.78237128
 -0.75597118 -0.7702959  -0.73729252 -0.71930416 -0.73467277 -0.74092329
 -0.70158702 -0.70525984 -0.71570275 -0.73532257 -0.72942278 -0.75404772
 -0.72485747 -0.7285961  -0.70226843 -0.71719017 -0.71676341 -0.74626028]
[0.35788955 0.34046119 0.33053462 0.3470402  0.32505144 0.32526481
 0.33630974 0.34457673 0.33047086 0.31686093 0.32725242 0.35606117
 0.33436896 0.34394457 0.34526115 0.33279296 0.3199675  0.3510897
 0.32058224 0.3276771  0.32626372 0.30817235 0.34472788 0.31712853
 0.30842137 0.29654945 0.35507631 0.32942342 0.33717681 0.30451353
 0.34121514 0.31296013 0.37499137 0.33545295 0.3631798  0.36668781
 0.32566059 0.33383464 0.36364036 0.33404285 0.35925414 0.33736783
 0.34934905 0.32083912 0.33695604 0.35000724 0.34270003 0.35915003]
[31 25 11 15  4 12 10 24 27 13  7 19 22 18 20 29 43 48 41 38 34 37 35 45
 47 46 40 44 42 39 33 36 26  9 21 28  1  3  5 23 17 32 14 16  2  8  6 30]
mdts_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50, 10)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.13117546 -0.13146293 -0.10073792 -0.10270541 -0.1115742  -0.10355381
 -0.09103071 -0.09565588 -0.12734026 -0.12264413 -0.09939791 -0.10673848
 -0.10344596 -0.10357702 -0.09304745 -0.08989949 -0.11947294 -0.12605248
 -0.10824166 -0.11467402 -0.10537916 -0.10440838 -0.09946527 -0.09423781
 -0.11885421 -0.12135152 -0.10803064 -0.10493312 -0.10084641 -0.1008823
 -0.09152479 -0.09341668 -0.09340107 -0.08882261 -0.091891   -0.09227492
 -0.08815019 -0.08774315 -0.09037358 -0.08630459 -0.09137256 -0.0925186
 -0.08764595 -0.08901155 -0.08729785 -0.08753185 -0.0900457  -0.08767235]
[0.03910656 0.03221738 0.04665458 0.04611401 0.04877018 0.04045692
 0.04770818 0.0472355  0.04886547 0.0383627  0.04464958 0.04457181
 0.04745876 0.03923429 0.04942136 0.04883474 0.04018035 0.03978078
 0.04273074 0.03812146 0.04072682 0.04152086 0.04969095 0.04859496
 0.03744225 0.03862471 0.04437403 0.03996855 0.04416669 0.04147011
 0.04657633 0.04370937 0.04466391 0.04598899 0.05152366 0.04357577
 0.04450453 0.04855557 0.05009846 0.04516117 0.04768777 0.04217948
 0.04514931 0.04623778 0.04668566 0.04254035 0.05069166 0.04881987]
[47 48 26 29 39 31 13 23 46 44 24 36 30 32 19 10 42 45 38 40 35 33 25 22
 41 43 37 34 27 28 15 21 20  8 16 17  7  6 12  1 14 18  4  9  2  3 11  5]
mdts_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50, 10)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.13363659 -0.14229734 -0.1146688  -0.11910623 -0.11602191 -0.11938583
 -0.10656823 -0.10691299 -0.13018404 -0.1434768  -0.11216933 -0.11575812
 -0.11018536 -0.1150539  -0.09896665 -0.09809106 -0.13653896 -0.13882183
 -0.12126616 -0.13006249 -0.12010402 -0.1176322  -0.10588043 -0.11208972
 -0.14442457 -0.13461479 -0.12199257 -0.12047412 -0.11800194 -0.11620038
 -0.10355978 -0.10543714 -0.10967594 -0.11119319 -0.1062168  -0.10756413
 -0.10989092 -0.1073983  -0.10540919 -0.10599172 -0.10441794 -0.1177809
 -0.10734623 -0.10674892 -0.09852107 -0.1033447  -0.09629165 -0.09731858]
[0.02865395 0.04022752 0.04011813 0.03278267 0.03943255 0.03181068
 0.03853109 0.04052698 0.03181648 0.03315802 0.03740462 0.04249089
 0.03698494 0.03254894 0.04194598 0.03873167 0.03757854 0.03545749
 0.03634961 0.03930437 0.03633035 0.03420118 0.04228779 0.0448859
 0.03452755 0.03333356 0.03442018 0.0384007  0.03556241 0.03757706
 0.03759635 0.03861252 0.03794913 0.04400194 0.03905333 0.04215572
 0.03976943 0.04039677 0.04099077 0.04172842 0.0387504  0.04184673
 0.04072585 0.04535291 0.03985967 0.04177415 0.04157211 0.04420909]
[42 46 26 34 29 35 14 16 41 47 25 28 22 27  5  3 44 45 38 40 36 31 11 24
 48 43 39 37 33 30  7 10 20 23 13 19 21 18  9 12  8 32 17 15  4  6  1  2]
shts_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50, 10)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.6072501  -0.62663437 -0.60022851 -0.63008142 -0.60881863 -0.63360944
 -0.59044069 -0.61621971 -0.6242312  -0.61866889 -0.60190227 -0.62009733
 -0.60815745 -0.63900858 -0.59566068 -0.6056447  -0.6686733  -0.66028906
 -0.65534625 -0.65873193 -0.64513068 -0.63600805 -0.6386392  -0.63946717
 -0.64096445 -0.66470731 -0.6571571  -0.66006349 -0.63518298 -0.65409224
 -0.63351013 -0.6459312  -0.59909087 -0.62021167 -0.59410283 -0.62692052
 -0.58488141 -0.60208655 -0.58650493 -0.60450376 -0.60035316 -0.61428628
 -0.59529669 -0.60567972 -0.57342781 -0.59542991 -0.58037099 -0.59238674]
[0.15539321 0.14436674 0.17497082 0.12934    0.13600706 0.13218952
 0.15071426 0.16929371 0.16044033 0.14612054 0.16128147 0.17022512
 0.16547505 0.13641183 0.1677715  0.14805883 0.16326914 0.15830222
 0.18900399 0.1370051  0.16654294 0.15274298 0.18893178 0.15172665
 0.16076494 0.14286783 0.1570968  0.1443241  0.14534792 0.14563931
 0.16645913 0.15442898 0.17044199 0.16690995 0.18592321 0.17581723
 0.17621767 0.17009452 0.17140002 0.17428748 0.17470785 0.15373323
 0.18326574 0.16756986 0.17529973 0.18036486 0.17988186 0.17134585]
[19 28 12 30 21 32  5 23 27 24 14 25 20 36 10 17 48 46 42 44 39 34 35 37
 38 47 43 45 33 41 31 40 11 26  7 29  3 15  4 16 13 22  8 18  1  9  2  6]
shts_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50, 10)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.5349648  -0.56155126 -0.53409807 -0.54822086 -0.54452618 -0.54323159
 -0.52733513 -0.54619755 -0.53563041 -0.55116384 -0.52873367 -0.53093371
 -0.55092257 -0.55364682 -0.50360719 -0.52677191 -0.56920217 -0.56828983
 -0.57547601 -0.57375562 -0.57151605 -0.58399525 -0.55353758 -0.57454467
 -0.561923   -0.58559663 -0.57949562 -0.57139743 -0.5868056  -0.56277898
 -0.56194876 -0.58180687 -0.51388064 -0.53563362 -0.60678948 -0.54397324
 -0.50837485 -0.52593996 -0.52318846 -0.52517731 -0.51930403 -0.54534939
 -0.51400173 -0.54819184 -0.51160725 -0.52527991 -0.51325548 -0.52508138]
[0.1190501  0.12898936 0.1180069  0.11039599 0.12001674 0.10072145
 0.11005459 0.12323293 0.11591865 0.1030304  0.13385463 0.12394881
 0.14007694 0.10862857 0.12830986 0.11667969 0.11821568 0.10531014
 0.12882619 0.09318922 0.12334107 0.09680991 0.13521499 0.09514293
 0.11546892 0.09574936 0.12145573 0.0993748  0.15439407 0.1078942
 0.13412665 0.12101641 0.1251719  0.11681375 0.19765074 0.11821089
 0.12480341 0.11929579 0.12977822 0.12634643 0.12576115 0.12902709
 0.13129619 0.1386459  0.12499956 0.1271479  0.12589042 0.13190917]
[18 32 17 27 23 21 14 25 19 29 15 16 28 31  1 13 37 36 42 40 39 45 30 41
 33 46 43 38 47 35 34 44  5 20 48 22  2 12  8 10  7 24  6 26  3 11  4  9]

*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 13087192)                   *
*                                                                           *
*****************************************************************************

Job ID: 13087192
Cluster: finisterrae3
User/Group: curso342/ulc
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 32
CPU Utilized: 3-02:25:27
CPU Efficiency: 99.11% of 3-03:05:36 core-walltime
Job Wall-clock time: 02:20:48
Memory Utilized: 8.32 GB
Memory Efficiency: 52.01% of 16.00 GB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************

