slurmstepd: info: Setting TMPDIR to /scratch/13087676. Previous errors about TMPDIR can be discarded
dwi_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.48172555 -0.51148643 -0.49277019 -0.52010694 -0.47485647 -0.5124044
 -0.49199954 -0.54696863 -0.50094909 -0.54019021 -0.48009515 -0.51260685
 -0.47895691 -0.50692433 -0.48438571 -0.51224071 -0.48004339 -0.50026501
 -0.48832946 -0.51965676 -0.49520965 -0.5439055  -0.48089396 -0.52922635
 -0.48345513 -0.51779642 -0.49386351 -0.5339455  -0.48589413 -0.51497714
 -0.51057034 -0.54384374 -0.51017444 -0.56379252 -0.49744299 -0.52409706
 -0.48072783 -0.50608561 -0.48786919 -0.52945512 -0.50212134 -0.52465361
 -0.48997735 -0.53356245 -0.50794605 -0.55191455 -0.51078542 -0.54349867
 -0.46480858 -0.4781876  -0.4734803  -0.497742   -0.49037752 -0.52048982
 -0.47529378 -0.49138643 -0.48385795 -0.51898917 -0.50630062 -0.53323873
 -0.46435042 -0.46989075 -0.46805733 -0.48616369 -0.49166418 -0.52361642
 -0.46967179 -0.48952754 -0.47803106 -0.50785764 -0.51705756 -0.54967397]
[0.05047259 0.0628703  0.04529167 0.06350525 0.05129362 0.06106274
 0.05679799 0.07780524 0.04737846 0.05914293 0.05989792 0.06419312
 0.04750494 0.07901756 0.04657685 0.062032   0.04981586 0.06179178
 0.05017879 0.05605486 0.04914303 0.07982496 0.05034977 0.06595265
 0.05748743 0.05941122 0.04988282 0.06352882 0.06051871 0.06329609
 0.04974082 0.07138996 0.05254227 0.06654257 0.05518963 0.07355379
 0.05416683 0.06303491 0.04970572 0.06035929 0.04939232 0.06035322
 0.05330105 0.06317388 0.05475369 0.06551494 0.05559887 0.05854876
 0.05776354 0.05911963 0.05398437 0.05646673 0.05261717 0.06172606
 0.05392278 0.06273635 0.05959013 0.06342669 0.06026561 0.06732582
 0.05664748 0.0590075  0.05734779 0.06358356 0.05283835 0.06782208
 0.05899231 0.06685304 0.05656738 0.06083258 0.05375241 0.06451156]
[16 46 30 55  7 48 29 69 36 65 13 49 11 40 19 47 12 35 23 54 32 68 15 60
 17 52 31 64 20 50 44 67 43 72 33 58 14 38 22 61 37 59 25 63 42 71 45 66
  2 10  6 34 26 56  8 27 18 53 39 62  1  5  3 21 28 57  4 24  9 41 51 70]
dwi_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.43327391 -0.4508485  -0.43504384 -0.45563224 -0.43444692 -0.43850501
 -0.4414899  -0.47541514 -0.44265056 -0.48390033 -0.43994624 -0.4521476
 -0.43025519 -0.44592599 -0.43314514 -0.45586652 -0.43651349 -0.44603332
 -0.43914807 -0.45285333 -0.44145819 -0.4781703  -0.43437406 -0.46372904
 -0.4384558  -0.46697271 -0.4534337  -0.4688429  -0.44755132 -0.46750366
 -0.4570751  -0.48647541 -0.47026961 -0.50821803 -0.46261722 -0.47243355
 -0.43656173 -0.45887468 -0.44468127 -0.464989   -0.46741497 -0.48052342
 -0.45094309 -0.47270578 -0.45770093 -0.50001941 -0.48048753 -0.4869616
 -0.42330655 -0.42878948 -0.42849671 -0.44241337 -0.44391404 -0.45824161
 -0.42780013 -0.45116197 -0.43891113 -0.46305344 -0.46339794 -0.48085519
 -0.42027082 -0.42015946 -0.42221007 -0.4337545  -0.45202157 -0.46548371
 -0.42589826 -0.43243696 -0.43211412 -0.4593626  -0.46466623 -0.47634769]
[0.04696032 0.03118992 0.038516   0.03298613 0.04770874 0.03647993
 0.04636992 0.04444472 0.04088394 0.03022742 0.04258255 0.04609563
 0.03724964 0.0385042  0.04314721 0.03879013 0.04529366 0.03978571
 0.03367434 0.02314269 0.04181702 0.03266729 0.03428774 0.04341593
 0.04158771 0.03841559 0.0412008  0.04235102 0.03833876 0.03521727
 0.04018928 0.02968517 0.04058987 0.03804055 0.03346702 0.02630644
 0.04298605 0.03408605 0.03734595 0.03333702 0.04525549 0.04343346
 0.0365622  0.04394796 0.03846559 0.02956884 0.04191061 0.03568764
 0.03668259 0.03399304 0.039306   0.0401828  0.03887536 0.03832031
 0.03914948 0.04051044 0.04449655 0.05181551 0.04522369 0.03337949
 0.03482638 0.03684186 0.03464069 0.04113266 0.04357754 0.03298551
 0.03714869 0.03914774 0.03772789 0.04140849 0.04587525 0.03669567]
[13 34 17 41 16 21 26 62 28 68 24 38  9 31 12 42 18 32 23 39 25 64 15 51
 20 55 40 58 33 57 43 69 59 72 48 60 19 46 30 53 56 66 35 61 44 71 65 70
  4  8  7 27 29 45  6 36 22 49 50 67  2  1  3 14 37 54  5 11 10 47 52 63]
wind_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-2.3795161  -2.45405906 -2.40628314 -2.5730158  -2.30964988 -2.48321933
 -2.45688456 -2.51533014 -2.45864301 -2.64493675 -2.412734   -2.57388135
 -2.41670185 -2.43755886 -2.37978759 -2.51218496 -2.3433633  -2.481658
 -2.41735474 -2.50510926 -2.41349603 -2.67995989 -2.3908013  -2.50430107
 -2.42580169 -2.68017474 -2.55196355 -2.76350241 -2.48684477 -2.69102338
 -2.55315234 -2.77463959 -2.63030199 -2.84814654 -2.47120888 -2.63609432
 -2.42978693 -2.63246132 -2.49320279 -2.7717166  -2.55336999 -2.66488248
 -2.50507616 -2.74312658 -2.5605637  -2.81871001 -2.5939425  -2.77339361
 -2.34498497 -2.407266   -2.36444484 -2.42989662 -2.50253131 -2.6398029
 -2.36142095 -2.47841504 -2.39573981 -2.54577441 -2.5518113  -2.70060341
 -2.35085872 -2.40307179 -2.34242457 -2.41585262 -2.44872546 -2.58966218
 -2.3452373  -2.44958068 -2.36419234 -2.52265713 -2.52071151 -2.65609922]
[0.39806206 0.3615149  0.42352649 0.36343303 0.38923383 0.45183608
 0.44618319 0.3261434  0.50981702 0.39645597 0.46117032 0.37185153
 0.40884306 0.39281289 0.39247453 0.38449585 0.40552674 0.40840802
 0.39880067 0.37872835 0.38253335 0.35824609 0.40422365 0.35551657
 0.41867404 0.41403895 0.50248822 0.32743489 0.41291023 0.32426939
 0.48705699 0.29129833 0.43962571 0.36846914 0.43001353 0.42289055
 0.41822202 0.3518528  0.47226519 0.38443122 0.44435049 0.32761701
 0.47282199 0.34821657 0.43215048 0.31382329 0.43702817 0.37375247
 0.42785847 0.34604753 0.41149108 0.35842213 0.4211433  0.33774642
 0.41774522 0.35789888 0.42793609 0.36955431 0.42990674 0.36391442
 0.43968695 0.38605476 0.41323914 0.36195285 0.41066123 0.3661602
 0.42420645 0.34591339 0.42365205 0.36649438 0.39500439 0.35887227]
[10 28 15 51  1 34 29 42 30 59 17 52 20 25 11 41  3 33 21 40 18 62 12 38
 22 63 47 67 35 64 48 70 55 72 31 57 23 56 36 68 49 61 39 66 50 71 54 69
  4 16  9 24 37 58  7 32 13 45 46 65  6 14  2 19 26 53  5 27  8 44 43 60]
wind_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-2.07554807 -2.13486405 -2.14154229 -2.215912   -2.11556518 -2.2150351
 -2.11127216 -2.24374088 -2.13762119 -2.33878991 -2.09848567 -2.2421534
 -2.05292427 -2.11158213 -2.07364972 -2.15861108 -2.07706886 -2.17230882
 -2.10468629 -2.15458886 -2.12829098 -2.25032336 -2.05647661 -2.31066582
 -2.15884515 -2.29264103 -2.20983898 -2.3770631  -2.17026947 -2.3151636
 -2.19473095 -2.44475799 -2.29218091 -2.47857968 -2.16984674 -2.33712311
 -2.13960205 -2.26547972 -2.18090764 -2.34516579 -2.20831643 -2.39446769
 -2.16356023 -2.33365766 -2.23589667 -2.46567654 -2.23068748 -2.36166825
 -2.04434969 -2.08525779 -2.0547207  -2.1227947  -2.15779834 -2.24437388
 -2.07652981 -2.134243   -2.10107576 -2.21706181 -2.22856702 -2.34034946
 -2.03500942 -2.06191252 -2.05523253 -2.10467656 -2.18148337 -2.26197007
 -2.04726381 -2.09969206 -2.06177098 -2.17989729 -2.23027622 -2.34158515]
[0.41364967 0.39784768 0.45330305 0.39435396 0.47385404 0.40346086
 0.44837391 0.41409593 0.45316593 0.4382825  0.4344171  0.44182443
 0.42299376 0.43143716 0.41550354 0.38665184 0.46425141 0.3943958
 0.44636225 0.36909563 0.46051992 0.39277422 0.41366742 0.43999379
 0.44765948 0.37526084 0.40748599 0.38647144 0.44231693 0.4357902
 0.44605082 0.40256199 0.44560172 0.37860285 0.43257139 0.3618965
 0.47166974 0.34837394 0.42953455 0.3427788  0.42182376 0.38257975
 0.45837212 0.35895532 0.42238031 0.44501935 0.41431509 0.35976728
 0.43985424 0.40558062 0.43431525 0.36068321 0.41964205 0.36222012
 0.43859862 0.39078577 0.41286311 0.36875338 0.44452096 0.42622226
 0.45185948 0.39389256 0.45045442 0.37771398 0.45173196 0.43827901
 0.43725297 0.38750801 0.41499743 0.36681786 0.43683739 0.36098856]
[11 26 29 45 22 44 20 52 27 63 15 51  4 21 10 32 13 37 19 30 24 54  7 59
 33 58 43 68 36 60 41 70 57 72 35 62 28 56 39 66 42 69 34 61 50 71 49 67
  2 14  5 23 31 53 12 25 17 46 47 64  1  9  6 18 40 55  3 16  8 38 48 65]
shww_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.92624166 -0.97348247 -0.97386609 -1.03378843 -0.97631996 -1.05746866
 -0.96744831 -1.01602799 -0.99386905 -1.0673872  -0.99937652 -1.10603901
 -0.93458594 -0.96274141 -0.94137895 -0.99927455 -1.0236292  -1.00087855
 -0.96187117 -1.00147944 -1.01860656 -1.03575511 -0.99518013 -1.0668387
 -0.98164364 -1.03864317 -1.00199229 -1.05496328 -1.01129985 -1.08588668
 -1.01031675 -1.10342658 -1.04804345 -1.14501636 -1.0029546  -1.06998721
 -0.97704607 -1.01556013 -0.98734337 -1.05526434 -0.999944   -1.06671276
 -1.00056781 -1.07507127 -1.04392143 -1.12637831 -1.03545221 -1.11198467
 -0.90458676 -0.91969093 -0.92547647 -0.96075334 -1.00041465 -0.9877652
 -0.92919355 -0.95155264 -0.97529208 -0.99553569 -1.02184623 -1.04718819
 -0.90360413 -0.90951225 -0.91517448 -0.93157867 -0.97177835 -1.02982779
 -0.92372307 -0.9500474  -0.94727236 -0.99348588 -0.99094937 -1.04013798]
[0.38841512 0.42534406 0.42088065 0.40155902 0.38586776 0.37980412
 0.40896839 0.38268692 0.416654   0.44105933 0.4199789  0.40364851
 0.38791224 0.39563582 0.39769714 0.41633132 0.55321103 0.41568596
 0.40247618 0.42007211 0.4345655  0.42676799 0.47295671 0.40937658
 0.39490025 0.36854536 0.38048398 0.37591295 0.40221104 0.35800773
 0.41163118 0.40135138 0.4021859  0.41038024 0.41619441 0.35619722
 0.38258352 0.35364495 0.39847691 0.3788677  0.38262208 0.34028174
 0.4122868  0.37077915 0.42357463 0.3857161  0.40437425 0.390642
 0.39176507 0.39411983 0.40439004 0.43759418 0.48341016 0.40648184
 0.41335531 0.40579371 0.45372416 0.432285   0.44646627 0.41445562
 0.38213662 0.36705573 0.40350937 0.38003101 0.43977547 0.44143223
 0.40599381 0.40138377 0.41744026 0.43869015 0.42990107 0.43357351]
[ 8 21 22 51 24 61 19 46 31 64 35 69 11 18 12 34 49 39 17 40 47 53 32 63
 26 54 41 59 44 67 43 68 58 72 42 65 25 45 27 60 36 62 38 66 56 71 52 70
  2  5  7 16 37 28  9 15 23 33 48 57  1  3  4 10 20 50  6 14 13 30 29 55]
shww_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.71920161 -0.75131982 -0.72818835 -0.7292214  -0.7946349  -0.82559721
 -0.74368744 -0.78381337 -0.74771855 -0.78739098 -0.76641483 -0.79458307
 -0.71662963 -0.74529698 -0.72324406 -0.74838296 -0.74895781 -0.7788714
 -0.73827457 -0.76056944 -0.74949059 -0.75407496 -0.74865203 -0.85062629
 -0.74580424 -0.78501411 -0.78191843 -0.80011705 -0.7656585  -0.79102229
 -0.77540716 -0.82884652 -0.7857628  -0.85645317 -0.76679489 -0.80015179
 -0.72904714 -0.77629584 -0.75135497 -0.79033743 -0.75609197 -0.81491716
 -0.75874106 -0.80329351 -0.77879804 -0.83881029 -0.77839571 -0.81475208
 -0.69962818 -0.68936972 -0.71245233 -0.73856141 -0.75182301 -0.74424639
 -0.6928391  -0.73310141 -0.7411694  -0.72875817 -0.75914192 -0.77552944
 -0.68706241 -0.68576908 -0.68658143 -0.7100971  -0.72981738 -0.77004222
 -0.70023146 -0.71830338 -0.70349881 -0.75596603 -0.76549454 -0.78501221]
[0.33768537 0.37501575 0.34697321 0.3379993  0.45451253 0.45526709
 0.34274819 0.35040138 0.35074207 0.3680838  0.34853286 0.35318167
 0.33866109 0.35858505 0.33649322 0.35009881 0.35099604 0.38267758
 0.34288612 0.31845546 0.37533269 0.34147524 0.35407741 0.4047714
 0.31579924 0.30286044 0.36128472 0.29935384 0.31861794 0.27749265
 0.35396794 0.32455543 0.32609548 0.32659206 0.33926592 0.30367781
 0.31864227 0.30805146 0.34907886 0.29828331 0.31909887 0.31120205
 0.32404356 0.30973948 0.34726484 0.32017575 0.31574606 0.28865235
 0.33620346 0.3273026  0.36365773 0.36321082 0.3684068  0.32848129
 0.33267421 0.34888456 0.39169082 0.3391186  0.35542081 0.36387528
 0.32815998 0.30844464 0.3271043  0.33564131 0.34442552 0.36100094
 0.34311369 0.33623704 0.33150099 0.37792136 0.3813332  0.34791149]
[13 33 15 18 62 68 24 54 28 58 44 61 11 26 14 29 31 52 21 41 32 36 30 71
 27 56 53 63 43 60 47 69 57 72 45 64 17 49 34 59 38 67 39 65 51 70 50 66
  6  4 10 22 35 25  5 20 23 16 40 48  3  1  2  9 19 46  7 12  8 37 42 55]
mdts_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.10022302 -0.09963654 -0.0982286  -0.09430044 -0.09546178 -0.1034589
 -0.10134081 -0.10214554 -0.1019669  -0.1006898  -0.09533149 -0.10185406
 -0.10518285 -0.09548028 -0.10111954 -0.09863845 -0.09744761 -0.10014758
 -0.10462239 -0.10110646 -0.10111213 -0.09939528 -0.09316343 -0.09952961
 -0.10347861 -0.09758793 -0.10118932 -0.09996914 -0.11294967 -0.10366859
 -0.10613531 -0.10101042 -0.10660636 -0.10603286 -0.108338   -0.11088329
 -0.101779   -0.09592555 -0.10249981 -0.0965595  -0.10663401 -0.09965393
 -0.1025581  -0.10045329 -0.10565901 -0.10242292 -0.11018163 -0.10154577
 -0.09511154 -0.09155515 -0.09719044 -0.09265343 -0.10171478 -0.09490429
 -0.09909998 -0.09530388 -0.1002161  -0.09587515 -0.10579671 -0.09904662
 -0.09510046 -0.08998069 -0.09596083 -0.0930654  -0.09901657 -0.09200135
 -0.0980401  -0.09319049 -0.09918606 -0.09530072 -0.10358543 -0.09687632]
[0.04799935 0.04161696 0.05038333 0.04044826 0.05263775 0.04550852
 0.04953009 0.04024235 0.04936905 0.04362871 0.0498877  0.04446594
 0.04887958 0.04561185 0.04877276 0.04038023 0.05241026 0.04359116
 0.04719237 0.04295667 0.04736251 0.04389074 0.05029795 0.04167521
 0.05070589 0.03885597 0.04509865 0.04099876 0.04714134 0.04323881
 0.04973756 0.04284067 0.05087224 0.04290622 0.05065274 0.04925937
 0.0516816  0.03887013 0.05033871 0.04030102 0.05229686 0.04098505
 0.04628298 0.0400573  0.05227437 0.03903241 0.05325812 0.03924801
 0.05029555 0.0462063  0.05103796 0.04502016 0.05209944 0.04544802
 0.05083972 0.04054058 0.04995037 0.04226067 0.04919657 0.04239525
 0.05282893 0.0451332  0.05265577 0.04373051 0.05242792 0.04567697
 0.05207652 0.04339233 0.0510161  0.0440714  0.05057694 0.04438293]
[39 34 26  8 15 57 47 53 52 41 14 51 62 16 45 27 23 37 61 43 44 32  6 33
 58 24 46 36 72 60 66 42 67 65 69 71 50 18 55 20 68 35 56 40 63 54 70 48
 11  2 22  4 49  9 30 13 38 17 64 29 10  1 19  5 28  3 25  7 31 12 59 21]
mdts_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.11273946 -0.12058219 -0.11669386 -0.11232938 -0.10220843 -0.10548169
 -0.12394559 -0.12064206 -0.12550065 -0.14041178 -0.10425851 -0.1028741
 -0.11439912 -0.11535412 -0.11510221 -0.11757132 -0.1082093  -0.10788063
 -0.1177022  -0.11721331 -0.11806439 -0.11561287 -0.10527584 -0.11018514
 -0.11563662 -0.11282066 -0.11831335 -0.11258284 -0.12206229 -0.11953658
 -0.11801127 -0.11786638 -0.12954718 -0.12791788 -0.12675311 -0.11942317
 -0.11408867 -0.11290814 -0.11461323 -0.11815504 -0.12421383 -0.12029212
 -0.11974247 -0.1189588  -0.12599539 -0.12307695 -0.12891416 -0.12975722
 -0.10749891 -0.1040048  -0.11428713 -0.10672075 -0.12758988 -0.10833012
 -0.1127333  -0.11006718 -0.11765602 -0.11385235 -0.1322611  -0.11264171
 -0.10635123 -0.10202023 -0.11012044 -0.10646904 -0.12234874 -0.11392613
 -0.11020397 -0.10521212 -0.11316231 -0.10986812 -0.13285252 -0.11201552]
[0.03935628 0.04362254 0.04524701 0.04220991 0.04764138 0.03870437
 0.04187907 0.03905071 0.03939171 0.07264369 0.0461512  0.03942108
 0.04001257 0.03953564 0.04266606 0.04063892 0.04454003 0.03789492
 0.03806474 0.03783193 0.03972008 0.03666184 0.04913273 0.04050357
 0.042439   0.0369036  0.0384304  0.03848769 0.04088095 0.04223348
 0.03977953 0.03715693 0.03751689 0.03736778 0.04022211 0.0350973
 0.04376532 0.03501913 0.03836874 0.0406267  0.03825601 0.0360259
 0.03868989 0.03812609 0.03703775 0.03875085 0.03847752 0.04567044
 0.04298514 0.03976062 0.04455467 0.03790277 0.04098319 0.04392269
 0.04120346 0.0382223  0.04060164 0.0369251  0.04161901 0.04259508
 0.04619314 0.03824407 0.04365459 0.0358961  0.0415072  0.04369456
 0.04620287 0.03703233 0.04231458 0.03747292 0.03227214 0.04395992]
[26 55 40 22  2  8 60 56 62 72  5  3 34 37 36 42 14 13 44 41 47 38  7 19
 39 27 49 23 57 52 46 45 68 66 64 51 32 28 35 48 61 54 53 50 63 59 67 69
 12  4 33 11 65 15 25 17 43 30 70 24  9  1 18 10 58 31 20  6 29 16 71 21]
shts_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.58229868 -0.6073333  -0.58807157 -0.61774193 -0.56648671 -0.6115641
 -0.58198836 -0.62513383 -0.59308792 -0.64448554 -0.55274673 -0.62639793
 -0.57084336 -0.59957056 -0.5732966  -0.61065714 -0.56366176 -0.59964901
 -0.58390022 -0.61302252 -0.58228455 -0.63340586 -0.56475953 -0.60906237
 -0.6144849  -0.62822599 -0.60695102 -0.66030895 -0.63194899 -0.65701927
 -0.62137461 -0.65644938 -0.62141349 -0.6894561  -0.62026802 -0.67530417
 -0.60079723 -0.63587412 -0.60983595 -0.64389735 -0.6473578  -0.67863655
 -0.60189442 -0.64625468 -0.62078114 -0.66812301 -0.64197254 -0.69225126
 -0.56300305 -0.57476825 -0.57175796 -0.59760526 -0.60294298 -0.63948687
 -0.56952142 -0.60359729 -0.58380004 -0.62947816 -0.60280903 -0.64791058
 -0.565367   -0.5713099  -0.56581799 -0.5811543  -0.58545953 -0.61772019
 -0.56833482 -0.58440463 -0.58048859 -0.60690327 -0.60479655 -0.64909632]
[0.1630223  0.14407877 0.17033833 0.15365129 0.16919981 0.1549581
 0.16531388 0.16155799 0.16256799 0.17555935 0.15077263 0.18659069
 0.1467232  0.1544861  0.1525634  0.15199756 0.16472354 0.19064438
 0.15844736 0.14664983 0.16791007 0.16795202 0.16528275 0.19193702
 0.16969617 0.14345269 0.17179264 0.17214895 0.15475556 0.15444214
 0.16820675 0.16381123 0.17302128 0.14785636 0.16662129 0.1398128
 0.15654295 0.14273216 0.16488499 0.14392367 0.17940577 0.15590889
 0.15517285 0.16383381 0.17294059 0.16963559 0.18922519 0.15300274
 0.14827391 0.15238355 0.16564013 0.15319004 0.17316412 0.18931345
 0.16887943 0.14960287 0.16895503 0.17379266 0.18785081 0.16467947
 0.14834078 0.14630162 0.15767288 0.15436781 0.17104047 0.16737279
 0.15441486 0.14823291 0.16881451 0.14672029 0.18080015 0.18172971]
[19 37 24 45  7 41 17 50 25 60  1 51 10 27 13 40  3 28 21 42 18 55  4 38
 43 52 36 67 54 66 48 65 49 71 46 69 29 56 39 59 62 70 30 61 47 68 58 72
  2 14 12 26 32 57  9 33 20 53 31 63  5 11  6 16 23 44  8 22 15 35 34 64]
shts_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layers': [(50, 20)], 'regressor__activation': [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.activation.Sigmoid'>], 'regressor__lr': [0.0005, 0.001, 0.01], 'regressor__epochs': [50, 100], 'regressor__batch_size': [16, 32]}]
[-0.51445126 -0.52869808 -0.52260748 -0.54784028 -0.49091164 -0.55860936
 -0.52906279 -0.56219325 -0.54468184 -0.55616653 -0.52190563 -0.54612617
 -0.50701345 -0.53334034 -0.50898218 -0.55374724 -0.50170497 -0.52430456
 -0.51968274 -0.55092288 -0.52369641 -0.54478655 -0.51179702 -0.5567846
 -0.52945568 -0.55969309 -0.53971011 -0.56067125 -0.56792669 -0.57213098
 -0.54165387 -0.59724995 -0.56870681 -0.60052712 -0.56029308 -0.59110535
 -0.51949848 -0.53465689 -0.53646136 -0.56917202 -0.55754122 -0.59174088
 -0.5370097  -0.5723205  -0.55100188 -0.57595598 -0.58025169 -0.60609019
 -0.50002456 -0.50482154 -0.50525429 -0.53209623 -0.54091429 -0.5466514
 -0.50801573 -0.53904015 -0.50745039 -0.55149423 -0.54784825 -0.5756157
 -0.49321707 -0.5074099  -0.50452295 -0.5214096  -0.52378756 -0.54914798
 -0.50874966 -0.51960266 -0.51420339 -0.53708022 -0.53937386 -0.56597998]
[0.11501807 0.10971092 0.13106589 0.10980488 0.1224287  0.12813804
 0.12440677 0.10231165 0.15462587 0.11789494 0.13741933 0.13269517
 0.1178399  0.10077388 0.12337063 0.13382941 0.11595872 0.13949244
 0.12614926 0.11544495 0.12243729 0.11529207 0.14217251 0.15814434
 0.12066561 0.10627084 0.12028204 0.10451794 0.13009839 0.11940462
 0.13575584 0.12184108 0.13465585 0.11950865 0.13938342 0.10343826
 0.11398781 0.10031636 0.13261299 0.12031232 0.13194651 0.0888553
 0.12887835 0.11464154 0.12973461 0.10575171 0.12884187 0.11235671
 0.11696969 0.11125006 0.12681479 0.11476909 0.13465158 0.12720462
 0.12745968 0.1127747  0.13243612 0.11171115 0.14023488 0.12652968
 0.10981485 0.11179519 0.11595069 0.11313485 0.13437816 0.12668976
 0.12118726 0.11268166 0.12800693 0.11476088 0.14447975 0.1237054 ]
[16 26 22 44  1 54 27 58 40 51 21 42  8 30 13 50  4 25 19 47 23 41 14 52
 28 55 37 57 60 63 39 70 61 71 56 68 17 31 32 62 53 69 33 64 48 66 67 72
  3  6  7 29 38 43 11 35 10 49 45 65  2  9  5 20 24 46 12 18 15 34 36 59]

*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 13087676)                   *
*                                                                           *
*****************************************************************************

Job ID: 13087676
Cluster: finisterrae3
User/Group: curso342/ulc
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 32
CPU Utilized: 3-22:08:42
CPU Efficiency: 96.49% of 4-01:34:24 core-walltime
Job Wall-clock time: 03:02:57
Memory Utilized: 15.68 GB
Memory Efficiency: 98.00% of 16.00 GB

*****************************************************************************

