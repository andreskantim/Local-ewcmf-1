slurmstepd: info: Setting TMPDIR to /scratch/13087189. Previous errors about TMPDIR can be discarded
dwi_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100,)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.50301966 -0.52104961 -0.50651442 -0.50399123 -0.50176798 -0.51733218
 -0.48985927 -0.48509847 -0.50510866 -0.51288626 -0.50498443 -0.49696358
 -0.50644833 -0.52217306 -0.47753558 -0.48562315 -0.51331808 -0.50646655
 -0.51617398 -0.50725207 -0.50601651 -0.52768294 -0.51408161 -0.51350967
 -0.52211849 -0.51039663 -0.51895669 -0.51956908 -0.51550125 -0.51507348
 -0.49969903 -0.50874534 -0.48069623 -0.4794596  -0.49044738 -0.49572642
 -0.49004789 -0.48103095 -0.49721378 -0.49331008 -0.47728696 -0.48573076
 -0.487636   -0.48467323 -0.48154685 -0.48499996 -0.49192474 -0.49431182]
[0.06553663 0.06468413 0.05535375 0.05266308 0.05357543 0.06133282
 0.06760911 0.06178821 0.05157905 0.06873769 0.05723576 0.05365401
 0.05811748 0.06850111 0.06329417 0.05080944 0.05621591 0.05850926
 0.05068168 0.05820144 0.05556453 0.06339987 0.0517107  0.07410439
 0.05507857 0.07129099 0.06001978 0.06904605 0.05413976 0.05352297
 0.05688381 0.06752952 0.05466456 0.05782823 0.05405806 0.05125184
 0.05600904 0.06249012 0.04337077 0.05493796 0.05845211 0.06074846
 0.06137813 0.05515377 0.04868089 0.06963004 0.0606155  0.0543201 ]
[24 45 31 25 23 42 13  9 27 35 26 20 29 47  2 10 36 30 41 32 28 48 38 37
 46 34 43 44 40 39 22 33  4  3 15 19 14  5 21 17  1 11 12  7  6  8 16 18]
dwi_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100,)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.444551   -0.46457419 -0.45806599 -0.45462319 -0.44771196 -0.45594715
 -0.43230451 -0.43022584 -0.4425179  -0.46060374 -0.45062967 -0.45351689
 -0.44388905 -0.45358822 -0.43309882 -0.43518703 -0.47026667 -0.45489175
 -0.46558337 -0.46609316 -0.45192957 -0.46714159 -0.45791823 -0.45387821
 -0.45234509 -0.46209008 -0.46702725 -0.46161426 -0.45234603 -0.45758281
 -0.4489981  -0.45314432 -0.42349827 -0.43241542 -0.44545113 -0.44319414
 -0.43174786 -0.43138011 -0.44249168 -0.43811702 -0.42543607 -0.43025863
 -0.45817764 -0.45152354 -0.42865397 -0.42877678 -0.4417857  -0.43859311]
[0.04287602 0.0374658  0.04596641 0.03444052 0.03696658 0.03389305
 0.04493407 0.03813816 0.04475982 0.04005615 0.04478945 0.03784454
 0.03817208 0.03612181 0.05231617 0.0335066  0.04516773 0.03837795
 0.03691346 0.036912   0.03984756 0.04804065 0.03335597 0.03871857
 0.03635098 0.03894452 0.04001638 0.03341758 0.03541154 0.04066663
 0.04233861 0.03043118 0.03787974 0.04190978 0.03199406 0.05141354
 0.04008806 0.04281391 0.0414515  0.03584379 0.03863377 0.03769611
 0.03041941 0.0238232  0.03849169 0.03722302 0.04154288 0.04720795]
[20 43 38 33 22 35  9  5 17 40 24 30 19 31 11 12 48 34 44 45 26 47 37 32
 27 42 46 41 28 36 23 29  1 10 21 18  8  7 16 13  2  6 39 25  3  4 15 14]
wind_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100,)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-2.41992302 -2.48228114 -2.38815749 -2.48556117 -2.43664694 -2.51144631
 -2.45286657 -2.49189816 -2.42364249 -2.49414659 -2.46622056 -2.5327913
 -2.43413053 -2.5197335  -2.47512452 -2.54710797 -2.53282061 -2.64135349
 -2.66592976 -2.7007141  -2.52459759 -2.64146334 -2.6678789  -2.76079985
 -2.5449975  -2.62086599 -2.75347354 -2.73055315 -2.53175806 -2.65443226
 -2.67008566 -2.78816899 -2.41321635 -2.45065064 -2.47195218 -2.50611428
 -2.44932922 -2.48377008 -2.50609356 -2.52562193 -2.39059336 -2.43690557
 -2.45472431 -2.51311268 -2.40590989 -2.49061526 -2.48198784 -2.54432852]
[0.40025989 0.37687131 0.40433757 0.41109954 0.38788535 0.39226413
 0.38688686 0.42882431 0.38238716 0.40272889 0.39662147 0.35984496
 0.37458832 0.40735228 0.36290479 0.36900205 0.45274526 0.4377851
 0.42820466 0.39143547 0.42793911 0.41792667 0.41108908 0.35653555
 0.46516897 0.37791277 0.39354334 0.39182169 0.3760279  0.37977073
 0.36485938 0.36406963 0.38224844 0.34426674 0.37435384 0.33361605
 0.36911733 0.35124024 0.35210484 0.35925527 0.37586089 0.33606414
 0.40042346 0.33920095 0.39567401 0.37824407 0.3505192  0.33096608]
[ 5 18  1 20  8 26 12 22  6 23 14 32  7 28 16 36 33 38 41 44 29 39 42 47
 35 37 46 45 31 40 43 48  4 11 15 25 10 19 24 30  2  9 13 27  3 21 17 34]
wind_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100,)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-2.09130918 -2.11237298 -2.1130655  -2.17804246 -2.14492019 -2.19124433
 -2.1075244  -2.1489843  -2.12444412 -2.13488722 -2.10227075 -2.18846744
 -2.12196184 -2.17496452 -2.11418396 -2.13110852 -2.20583064 -2.24552213
 -2.37465805 -2.40140928 -2.22443547 -2.2851053  -2.32128463 -2.36430314
 -2.2430208  -2.24710356 -2.36435681 -2.34747643 -2.24078223 -2.27016212
 -2.32262117 -2.39642399 -2.06155884 -2.11854555 -2.13521351 -2.16871394
 -2.11525838 -2.14499977 -2.17162642 -2.24851478 -2.13921884 -2.14599515
 -2.14457988 -2.15130379 -2.11804436 -2.15324767 -2.15915638 -2.18846936]
[0.38907928 0.36028469 0.40136831 0.37073228 0.41308357 0.4123399
 0.45746724 0.37321861 0.4198649  0.39033882 0.37231052 0.42450654
 0.41503407 0.42630411 0.41454372 0.41977427 0.45041665 0.43136971
 0.47768867 0.42336925 0.42420792 0.37593846 0.44577631 0.3702631
 0.43080064 0.39431475 0.43802176 0.43004374 0.46859209 0.4324268
 0.37501916 0.39082251 0.42682804 0.40251044 0.43472284 0.40704118
 0.42006315 0.41251064 0.38839007 0.36801765 0.40420611 0.38184757
 0.42722318 0.41747053 0.44500947 0.40440766 0.42042747 0.41043797]
[ 2  5  6 28 18 31  4 21 12 14  3 29 11 27  7 13 32 36 46 48 33 40 41 44
 35 37 45 43 34 39 42 47  1 10 15 25  8 19 26 38 16 20 17 22  9 23 24 30]
shww_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100,)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.93745064 -0.96585327 -0.96560795 -0.98071344 -0.95979935 -0.99394952
 -0.9357267  -0.97730369 -0.94216028 -0.97369435 -0.96617901 -0.97882153
 -0.95035354 -0.97786777 -0.94568909 -0.99260659 -1.02235293 -1.04721921
 -1.06378932 -1.05970233 -1.03739395 -1.02468726 -1.07565506 -1.05401948
 -1.05104809 -1.02324975 -1.07193903 -1.03733909 -1.0177901  -1.03256708
 -1.06666378 -1.07741816 -0.96460368 -0.94994614 -0.99111474 -1.00309857
 -0.96353968 -0.96933014 -1.05640821 -1.01246995 -0.94022988 -0.9693896
 -1.00868962 -0.98285095 -0.9639528  -0.9768903  -1.00636615 -1.00605407]
[0.36795836 0.36435828 0.35643418 0.38527912 0.40467215 0.35682531
 0.36645775 0.33717027 0.39015391 0.3824767  0.37365164 0.3469071
 0.37944031 0.36389623 0.38744578 0.39647936 0.41675677 0.37463827
 0.3975134  0.35166593 0.39014508 0.36531141 0.35908864 0.34773331
 0.43732818 0.3738699  0.38007769 0.38377558 0.3996422  0.40635449
 0.37149954 0.36719162 0.42387927 0.38702247 0.4264628  0.37874047
 0.4212951  0.38375061 0.35834869 0.34497265 0.38678872 0.40627963
 0.37873946 0.38773647 0.39319198 0.40092394 0.3722009  0.41183491]
[ 2 13 12 22  8 26  1 19  4 17 14 21  7 20  5 25 33 39 44 43 38 35 47 41
 40 34 46 37 32 36 45 48 11  6 24 27  9 15 42 31  3 16 30 23 10 18 29 28]
shww_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100,)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.72892916 -0.76067158 -0.73743646 -0.74402587 -0.73838079 -0.75914009
 -0.70435788 -0.72971313 -0.72716332 -0.75374005 -0.74080834 -0.74337794
 -0.73704085 -0.75115234 -0.71303492 -0.73328731 -0.78796169 -0.78327755
 -0.79619223 -0.83457923 -0.77820897 -0.79391902 -0.8198698  -0.8087994
 -0.79193907 -0.7787862  -0.82645504 -0.81264841 -0.79119156 -0.80296492
 -0.80389911 -0.81247477 -0.72387417 -0.71768595 -0.75006621 -0.7617188
 -0.71885004 -0.74796688 -0.79304996 -0.78557208 -0.7123393  -0.74120657
 -0.79143373 -0.77217007 -0.72227823 -0.74916041 -0.77861675 -0.76489787]
[0.31404806 0.31858279 0.30137133 0.30204365 0.30584205 0.31240832
 0.29535626 0.30677379 0.30537513 0.3008465  0.31333413 0.31427296
 0.31321195 0.30989053 0.32766025 0.31747233 0.32955788 0.3063548
 0.29491924 0.31988177 0.31641571 0.30224421 0.29172054 0.27612725
 0.34727282 0.30450342 0.29114397 0.32494948 0.32470439 0.30156141
 0.30018991 0.2967103  0.31183077 0.32070997 0.31136388 0.32047933
 0.31964433 0.33430835 0.3156275  0.29914043 0.32546496 0.30130908
 0.32586729 0.32875214 0.3182027  0.32211116 0.29250739 0.28023562]
[ 9 25 13 18 14 24  1 10  8 23 15 17 12 22  3 11 34 32 40 48 29 39 46 43
 37 31 47 45 35 41 42 44  7  4 21 26  5 19 38 33  2 16 36 28  6 20 30 27]
mdts_sin
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100,)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.14010858 -0.16926722 -0.13525443 -0.11317803 -0.12332983 -0.12946854
 -0.09616105 -0.10052941 -0.14363902 -0.15400983 -0.13264544 -0.11189499
 -0.1239788  -0.11578904 -0.09022676 -0.09967925 -0.14303354 -0.15420744
 -0.13382377 -0.12721777 -0.12380153 -0.12577258 -0.1061181  -0.10521131
 -0.13987659 -0.1504365  -0.12706945 -0.12723925 -0.12119305 -0.11383211
 -0.10303082 -0.10545209 -0.09549875 -0.09181654 -0.10505705 -0.09803801
 -0.09745431 -0.09255254 -0.09945096 -0.09590165 -0.09296398 -0.08938494
 -0.09971286 -0.09326657 -0.09205317 -0.08900218 -0.09656284 -0.09483562]
[0.03782218 0.0672169  0.03471508 0.03683434 0.04665585 0.03703308
 0.04520661 0.04367035 0.03718083 0.03578429 0.03985801 0.04054556
 0.04120163 0.04626076 0.04091582 0.04318636 0.03702879 0.03665042
 0.03990219 0.03224867 0.0395957  0.03066376 0.03910312 0.04173856
 0.03710091 0.04020431 0.03728155 0.04184229 0.03347214 0.03699577
 0.0440715  0.04573168 0.04447392 0.04632938 0.04224055 0.04082422
 0.04312619 0.04405778 0.04134006 0.04475405 0.0456014  0.04548156
 0.04459506 0.0400026  0.04431798 0.04199291 0.04757932 0.0425978 ]
[42 48 40 26 30 37 12 19 44 46 38 25 32 28  3 17 43 47 39 35 31 33 24 22
 41 45 34 36 29 27 20 23 10  4 21 15 14  6 16 11  7  2 18  8  5  1 13  9]
mdts_cos
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100,)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.14780053 -0.16927016 -0.13825484 -0.12728596 -0.13900332 -0.13141736
 -0.10295597 -0.109121   -0.14685503 -0.16865821 -0.14460843 -0.12543384
 -0.1275664  -0.1327707  -0.10363263 -0.11220024 -0.15278853 -0.15756852
 -0.14997173 -0.13781422 -0.14206926 -0.13610652 -0.11631007 -0.12378825
 -0.15548241 -0.16575669 -0.14709575 -0.13882947 -0.13863844 -0.13464586
 -0.11452831 -0.1092983  -0.1068013  -0.10733645 -0.12132175 -0.11480714
 -0.11085704 -0.11613553 -0.10998749 -0.11146899 -0.10384364 -0.10768112
 -0.10643693 -0.1107784  -0.1058348  -0.10612369 -0.10519008 -0.10400429]
[0.02905874 0.03915165 0.03663021 0.03051695 0.03604802 0.03340555
 0.03376058 0.04063677 0.02990103 0.0493331  0.03705798 0.03598425
 0.03057012 0.04254727 0.03589882 0.03947467 0.03000284 0.02924988
 0.03312028 0.0330208  0.03235071 0.02854584 0.0357751  0.03090473
 0.02913958 0.03156018 0.03097217 0.03313252 0.03210004 0.03491028
 0.03905381 0.03358866 0.04137191 0.03558514 0.03105718 0.03455141
 0.03549833 0.03532971 0.03546788 0.03524246 0.0380834  0.03457805
 0.03513172 0.03364033 0.03999749 0.03529558 0.03820619 0.03815853]
[41 48 33 26 36 28  1 12 39 47 38 25 27 29  2 18 43 45 42 32 37 31 22 24
 44 46 40 35 34 30 19 13  9 10 23 20 16 21 14 17  3 11  8 15  6  7  5  4]
shts_max
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100,)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.59392415 -0.63150875 -0.59520539 -0.63543927 -0.60616489 -0.63993692
 -0.60093413 -0.59463688 -0.59471705 -0.62579869 -0.61412445 -0.62376437
 -0.6050066  -0.64880504 -0.57825049 -0.60563913 -0.65988002 -0.64767049
 -0.67398717 -0.68613133 -0.67061309 -0.63939604 -0.65561913 -0.67694605
 -0.64946142 -0.65850117 -0.67564545 -0.66163503 -0.66161163 -0.64544736
 -0.65230254 -0.66522891 -0.57426997 -0.60734949 -0.61200219 -0.60994959
 -0.58899697 -0.59605743 -0.6190903  -0.62079302 -0.57592062 -0.5938146
 -0.60802617 -0.60987984 -0.57834266 -0.59670981 -0.60765483 -0.61480716]
[0.15362433 0.122562   0.14939157 0.12052343 0.15741924 0.12360576
 0.14771926 0.14679646 0.15017094 0.12343163 0.15534597 0.13509338
 0.14251318 0.1377269  0.14268342 0.14083966 0.14254483 0.12467411
 0.15400388 0.11027746 0.12759389 0.12907591 0.14351452 0.11430543
 0.13281276 0.12810352 0.14115976 0.12688613 0.16035415 0.11975791
 0.13567628 0.11781759 0.14162662 0.15032502 0.13287164 0.135948
 0.14222658 0.13614117 0.13908042 0.14503848 0.14406893 0.14376567
 0.13878223 0.13373729 0.14505481 0.14165037 0.15825226 0.1448982 ]
[ 7 29 10 30 16 32 13  8  9 28 23 27 14 35  3 15 40 34 45 48 44 31 38 47
 36 39 46 42 41 33 37 43  1 17 22 21  5 11 25 26  2  6 19 20  4 12 18 24]
shts_med
[{'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100,)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.53563748 -0.56527932 -0.53342292 -0.56532086 -0.53385706 -0.55221824
 -0.52277678 -0.54052157 -0.53197123 -0.5674566  -0.53696445 -0.56387096
 -0.5460097  -0.56755031 -0.52365263 -0.53942791 -0.57277035 -0.56864654
 -0.60525964 -0.57629289 -0.57902878 -0.57067895 -0.57791374 -0.57293396
 -0.58443305 -0.5817295  -0.60282093 -0.58078861 -0.56668604 -0.57075745
 -0.58329307 -0.56290844 -0.50717649 -0.52810191 -0.55011587 -0.5424646
 -0.51569252 -0.52460937 -0.53877789 -0.55748523 -0.50895576 -0.52243628
 -0.54606819 -0.53727013 -0.52598493 -0.54910606 -0.53718523 -0.55454478]
[0.10905161 0.09918675 0.10095425 0.10636333 0.10974044 0.10609158
 0.11526289 0.10711636 0.11477718 0.1108938  0.10643349 0.10147879
 0.1398565  0.10181183 0.1159965  0.10179431 0.10346046 0.09938594
 0.10631987 0.09421455 0.11224673 0.09618002 0.10954901 0.100705
 0.11484777 0.08400009 0.10295503 0.09227301 0.10213031 0.10762365
 0.1188755  0.08668545 0.11828892 0.10674221 0.11205452 0.10866304
 0.11070039 0.11542548 0.10782366 0.09878715 0.10955264 0.11735191
 0.11937139 0.09593286 0.1236648  0.1241868  0.1175682  0.10259233]
[13 30 11 31 12 25  5 19 10 33 14 29 21 34  6 18 38 35 48 40 42 36 41 39
 46 44 47 43 32 37 45 28  1  9 24 20  3  7 17 27  2  4 22 16  8 23 15 26]

*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 13087189)                   *
*                                                                           *
*****************************************************************************

Job ID: 13087189
Cluster: finisterrae3
User/Group: curso342/ulc
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 32
CPU Utilized: 2-08:38:43
CPU Efficiency: 98.97% of 2-09:14:08 core-walltime
Job Wall-clock time: 01:47:19
Memory Utilized: 8.13 GB
Memory Efficiency: 50.81% of 16.00 GB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************

