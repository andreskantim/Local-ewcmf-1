slurmstepd: info: Setting TMPDIR to /scratch/13087191. Previous errors about TMPDIR can be discarded
dwi_sin
[{'regressor': [MLPRegressor(early_stopping=True, max_iter=2000)], 'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.51139407 -0.52307682 -0.50304915 -0.50990916 -0.51668102 -0.51497591
 -0.49258759 -0.49688497 -0.51363232 -0.52752203 -0.49403531 -0.49198372
 -0.51120163 -0.51867007 -0.49824789 -0.50295458 -0.50615117 -0.51730283
 -0.49796886 -0.50838545 -0.51103938 -0.51772236 -0.51274199 -0.51053973
 -0.49891912 -0.5148892  -0.50733834 -0.50212668 -0.50264745 -0.50315555
 -0.49608592 -0.50564944 -0.47273692 -0.47745932 -0.4773663  -0.47837736
 -0.47558583 -0.47780049 -0.48785141 -0.48566209 -0.48165105 -0.4818923
 -0.48711239 -0.4830558  -0.47657572 -0.48558418 -0.47592115 -0.48252611]
[0.05496276 0.06346899 0.05828119 0.0633354  0.05234303 0.07952831
 0.04594638 0.05853222 0.06201841 0.06300436 0.0570992  0.06429338
 0.05492495 0.0530124  0.05635726 0.06806079 0.05410675 0.06737174
 0.06819231 0.06067646 0.05196609 0.04986903 0.04703069 0.05115227
 0.06241514 0.07410201 0.05791818 0.06008515 0.04961357 0.06364703
 0.05203595 0.04502083 0.06374145 0.05361125 0.06227951 0.05589145
 0.06281053 0.06267525 0.06583981 0.05833311 0.06101594 0.0666603
 0.05947865 0.05978008 0.06350516 0.05484031 0.05485236 0.06651452]
[38 47 28 34 43 42 18 21 40 48 19 17 37 46 23 27 31 44 22 33 36 45 39 35
 24 41 32 25 26 29 20 30  1  6  5  8  2  7 16 14  9 10 15 12  4 13  3 11]
dwi_cos
[{'regressor': [MLPRegressor(early_stopping=True, max_iter=2000)], 'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.46255413 -0.46088463 -0.45296616 -0.43914381 -0.46087074 -0.46375882
 -0.43748541 -0.43542137 -0.45199976 -0.46258692 -0.44677768 -0.45196544
 -0.46070297 -0.46231043 -0.43315407 -0.43858657 -0.45450244 -0.44999668
 -0.46203679 -0.4515964  -0.44941018 -0.46227539 -0.44901047 -0.4398207
 -0.46143883 -0.44618331 -0.45194958 -0.45859975 -0.45064761 -0.4709022
 -0.43832636 -0.44892409 -0.42319457 -0.43051577 -0.44755454 -0.44209742
 -0.42871242 -0.43417743 -0.45143048 -0.44391855 -0.42312065 -0.43019168
 -0.44858644 -0.44187874 -0.43021118 -0.42590626 -0.43918022 -0.43683039]
[0.04343758 0.0306403  0.03991594 0.03753162 0.03431622 0.03271606
 0.03445019 0.03727204 0.04009371 0.0396257  0.03624638 0.03821832
 0.04463757 0.04575385 0.03154413 0.03848767 0.04032275 0.04777578
 0.04827948 0.04489387 0.04280383 0.04105207 0.03456762 0.03508779
 0.03417325 0.03312534 0.043933   0.03924809 0.03196386 0.0361472
 0.0332074  0.03822434 0.03660703 0.03358867 0.04408535 0.0363456
 0.03815018 0.03822464 0.04838592 0.03992131 0.03158231 0.03415692
 0.03865255 0.05021105 0.03718617 0.0311723  0.037348   0.04119442]
[45 40 35 15 39 47 12 10 34 46 22 33 38 44  8 14 36 28 42 31 27 43 26 17
 41 21 32 37 29 48 13 25  2  7 23 19  4  9 30 20  1  5 24 18  6  3 16 11]
wind_max
[{'regressor': [MLPRegressor(early_stopping=True, max_iter=2000)], 'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-2.44506333 -2.47876282 -2.48741285 -2.51324425 -2.47799475 -2.50374996
 -2.4281431  -2.55206429 -2.47033068 -2.48797401 -2.52031204 -2.52638817
 -2.47765136 -2.58537746 -2.46038796 -2.46408996 -2.68515147 -2.73616916
 -2.68350092 -2.70709506 -2.6046381  -2.71424344 -2.57547551 -2.63248555
 -2.67172248 -2.71478017 -2.61092648 -2.71236698 -2.60571946 -2.70557304
 -2.53934701 -2.62001705 -2.45578885 -2.56884189 -2.46497504 -2.52725766
 -2.44718623 -2.49025381 -2.55850379 -2.56748706 -2.44343251 -2.54310738
 -2.40317891 -2.52801961 -2.44503144 -2.53944654 -2.48511029 -2.51127749]
[0.42095127 0.35036532 0.36216362 0.38120288 0.34971826 0.34880092
 0.3980277  0.39093125 0.38461878 0.33827533 0.4616801  0.36468201
 0.41436666 0.35235134 0.38015653 0.38643025 0.47645396 0.35886311
 0.45693296 0.35414996 0.39720421 0.39608367 0.4035122  0.3565347
 0.46501218 0.33330245 0.41376201 0.40954231 0.39984213 0.37200719
 0.41227924 0.37947161 0.44529727 0.37055606 0.35000003 0.36219083
 0.34205578 0.41006639 0.33581103 0.37905344 0.35332939 0.36368943
 0.40212587 0.37417616 0.41055676 0.35140935 0.38233059 0.38355087]
[ 5 14 16 21 13 19  2 29 11 17 22 23 12 34  8  9 42 48 41 44 35 46 33 39
 40 47 37 45 36 43 26 38  7 32 10 24  6 18 30 31  3 28  1 25  4 27 15 20]
wind_med
[{'regressor': [MLPRegressor(early_stopping=True, max_iter=2000)], 'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-2.12824188 -2.18061964 -2.17320787 -2.24333509 -2.20509616 -2.29320151
 -2.18964468 -2.17117244 -2.10773024 -2.16658432 -2.1455063  -2.2008818
 -2.12773668 -2.18475058 -2.15403312 -2.15778756 -2.24881737 -2.30060386
 -2.3161421  -2.33956254 -2.28234246 -2.32360568 -2.24662838 -2.28402993
 -2.23946129 -2.40154095 -2.29084536 -2.34376808 -2.26603592 -2.33047809
 -2.22870675 -2.27910127 -2.10237116 -2.15216395 -2.15252312 -2.20725347
 -2.09279959 -2.14947852 -2.15039205 -2.17297081 -2.1370053  -2.17573937
 -2.15092565 -2.18172327 -2.07078868 -2.18252979 -2.20994478 -2.24937448]
[0.36137247 0.4214589  0.36884992 0.47583635 0.4283438  0.42206325
 0.4630729  0.3891382  0.40968933 0.4079371  0.37189902 0.4294361
 0.40181259 0.41746423 0.39493271 0.42923758 0.46270943 0.3945208
 0.39970531 0.39703155 0.47034272 0.38053451 0.45968026 0.39782186
 0.46108953 0.40131393 0.49915516 0.37376845 0.44561655 0.44397278
 0.42611179 0.40420026 0.36943417 0.40402302 0.433205   0.37796103
 0.39615502 0.39578636 0.45781136 0.41129707 0.39847043 0.4073148
 0.39272412 0.40752236 0.43721703 0.42438149 0.37439743 0.41024916]
[ 6 21 19 32 27 41 25 17  4 16  8 26  5 24 14 15 34 42 43 46 38 44 33 39
 31 48 40 47 36 45 30 37  3 12 13 28  2  9 10 18  7 20 11 22  1 23 29 35]
shww_max
[{'regressor': [MLPRegressor(early_stopping=True, max_iter=2000)], 'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.96869489 -0.9953948  -0.98572015 -0.97277289 -0.97212209 -0.98810838
 -0.95317986 -0.98028522 -0.96276398 -0.97294121 -0.99036054 -0.9532705
 -0.98799091 -0.99062762 -0.95080114 -0.98608571 -1.03132634 -1.04303217
 -1.03301328 -1.05567984 -1.0219898  -1.03905384 -1.02414193 -1.06724445
 -1.0285336  -1.04812461 -1.04035037 -1.02447971 -1.04021041 -1.01256799
 -1.01507758 -1.01582517 -0.92773063 -0.96070285 -0.94833692 -0.98398637
 -0.9441979  -0.97037623 -0.9597026  -0.96336417 -0.93879466 -0.93636385
 -0.96764755 -0.95230143 -0.92111213 -0.94526735 -0.95534846 -1.02776509]
[0.39161545 0.37587546 0.41850478 0.39149539 0.41353702 0.42463962
 0.42873154 0.3835994  0.38616192 0.40471232 0.43065634 0.38338944
 0.44031628 0.38725099 0.39730041 0.41723574 0.4003838  0.4085091
 0.38805363 0.3619615  0.37802226 0.38452505 0.40191879 0.38977191
 0.38659309 0.39120986 0.3878128  0.39965326 0.37561681 0.38413465
 0.38777391 0.35006876 0.39349296 0.42207955 0.41910834 0.38248619
 0.4264859  0.42307506 0.43948838 0.39780528 0.43000087 0.36689965
 0.45154076 0.406264   0.39550065 0.41100739 0.42143002 0.43622791]
[18 31 25 21 20 28 10 23 15 22 29 11 27 30  8 26 40 45 41 47 35 42 36 48
 39 46 44 37 43 32 33 34  2 14  7 24  5 19 13 16  4  3 17  9  1  6 12 38]
shww_med
[{'regressor': [MLPRegressor(early_stopping=True, max_iter=2000)], 'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.74457686 -0.74764178 -0.73780118 -0.73284257 -0.72279061 -0.74677296
 -0.72199326 -0.71849884 -0.75285546 -0.7432424  -0.74732443 -0.73746014
 -0.74489794 -0.74397467 -0.73520226 -0.71318432 -0.80547713 -0.8001606
 -0.79646333 -0.78412261 -0.76243746 -0.78107429 -0.77686845 -0.79148071
 -0.78218578 -0.80051149 -0.81378529 -0.78650716 -0.79246168 -0.813925
 -0.77528699 -0.77162796 -0.69673352 -0.72931262 -0.70465739 -0.72061438
 -0.69766581 -0.69841319 -0.7471597  -0.73983437 -0.69763302 -0.71395914
 -0.72257536 -0.73357214 -0.69723845 -0.70193444 -0.7240254  -0.71583814]
[0.33004968 0.3174454  0.34375646 0.32730477 0.29810381 0.32183415
 0.34433013 0.31914159 0.31123724 0.30570131 0.34063357 0.35748027
 0.33634707 0.3074436  0.347404   0.32440336 0.34911088 0.30815932
 0.31139877 0.31373069 0.30261099 0.30333105 0.32358489 0.28322998
 0.31156642 0.29319796 0.35658034 0.31649366 0.34206709 0.31361025
 0.33346755 0.28644089 0.32049556 0.360384   0.32341607 0.33585775
 0.33443559 0.32921781 0.35973708 0.34102138 0.33143154 0.33022617
 0.3705703  0.3459657  0.34888834 0.33450096 0.36116468 0.32998808]
[26 31 22 18 15 28 13 11 32 24 30 21 27 25 20  8 46 44 43 39 33 37 36 41
 38 45 47 40 42 48 35 34  1 17  7 12  4  5 29 23  3  9 14 19  2  6 16 10]
mdts_sin
[{'regressor': [MLPRegressor(early_stopping=True, max_iter=2000)], 'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.14554159 -0.15957657 -0.11874084 -0.11383118 -0.11294858 -0.11357982
 -0.09936164 -0.09796523 -0.15052606 -0.15626543 -0.11282613 -0.11010492
 -0.11520318 -0.10582118 -0.09308871 -0.09654977 -0.11927024 -0.12722952
 -0.12443521 -0.1144105  -0.11539764 -0.10902485 -0.10281479 -0.09969629
 -0.12778185 -0.12174346 -0.12282754 -0.11697848 -0.1070345  -0.10624451
 -0.10262289 -0.09376256 -0.09683458 -0.09110785 -0.09930574 -0.09325871
 -0.09708892 -0.08989145 -0.0907978  -0.09000257 -0.09283423 -0.08984448
 -0.09699086 -0.0901886  -0.08904797 -0.08842516 -0.08966429 -0.08788161]
[0.03909296 0.04369209 0.04165127 0.04376496 0.04334529 0.03449924
 0.04563585 0.04123721 0.03889061 0.05178716 0.04335509 0.04089378
 0.04062533 0.0437119  0.04647314 0.04277032 0.03700415 0.03583576
 0.03317945 0.03442524 0.0356334  0.03793219 0.04013824 0.0383978
 0.03816741 0.03187075 0.0366954  0.03704325 0.039104   0.03490551
 0.04621436 0.0437327  0.04511339 0.0454886  0.04248606 0.04173036
 0.04227006 0.04105666 0.04949232 0.04674564 0.04606679 0.04538812
 0.04496502 0.04402589 0.04574606 0.04559784 0.04561094 0.04592124]
[45 48 38 33 31 32 21 19 46 47 30 29 35 25 12 15 39 43 42 34 36 28 24 22
 44 40 41 37 27 26 23 14 16 10 20 13 18  6  9  7 11  5 17  8  3  2  4  1]
mdts_cos
[{'regressor': [MLPRegressor(early_stopping=True, max_iter=2000)], 'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.15424042 -0.16074327 -0.13111078 -0.13038592 -0.12858265 -0.11958447
 -0.10989911 -0.1085325  -0.15800392 -0.16534521 -0.12495755 -0.12028428
 -0.13191565 -0.11507451 -0.10376098 -0.10645368 -0.13709888 -0.14685018
 -0.14159003 -0.13579674 -0.13428975 -0.12778116 -0.1163986  -0.11086232
 -0.13848707 -0.13990835 -0.14013182 -0.13072728 -0.12662161 -0.11956276
 -0.11163815 -0.10929192 -0.11076805 -0.11269633 -0.11273486 -0.11492768
 -0.11227991 -0.11399374 -0.1012883  -0.10819258 -0.10582357 -0.10562564
 -0.10714794 -0.11167967 -0.10059974 -0.10734217 -0.09892655 -0.09996944]
[0.03001972 0.03216327 0.03216695 0.03548658 0.03004896 0.03732433
 0.03786632 0.03603759 0.0346992  0.04220679 0.0356929  0.03298169
 0.0391604  0.03470476 0.03690534 0.03716863 0.03066889 0.02960291
 0.0335411  0.02905891 0.03425437 0.03150662 0.03740209 0.03488869
 0.02986608 0.03239129 0.02889341 0.02900915 0.03331506 0.03066852
 0.03682646 0.03538577 0.03898167 0.03496844 0.03468133 0.03280347
 0.03823673 0.03657105 0.04106386 0.04427197 0.03506928 0.03649418
 0.03673066 0.03568712 0.0397856  0.03404636 0.04230899 0.04127373]
[45 47 35 33 32 27 14 12 46 48 29 28 36 24  5  8 39 44 43 38 37 31 25 16
 40 41 42 34 30 26 17 13 15 20 21 23 19 22  4 11  7  6  9 18  3 10  1  2]
shts_max
[{'regressor': [MLPRegressor(early_stopping=True, max_iter=2000)], 'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.61004445 -0.62348878 -0.60536557 -0.64468879 -0.61668012 -0.61214084
 -0.58887963 -0.60388753 -0.61693327 -0.63711921 -0.62842788 -0.62235291
 -0.61297985 -0.64659654 -0.5926025  -0.6123806  -0.6592514  -0.65352538
 -0.66746243 -0.65915942 -0.66276238 -0.64520581 -0.63806729 -0.64051964
 -0.64433032 -0.6498667  -0.63547003 -0.66520305 -0.63158527 -0.64643003
 -0.62006292 -0.64002164 -0.5592649  -0.59237664 -0.61464712 -0.6170735
 -0.57291552 -0.59962883 -0.59750662 -0.59623485 -0.5676249  -0.5830356
 -0.61070282 -0.60181425 -0.58302908 -0.61009076 -0.57630069 -0.6040578 ]
[0.15087577 0.13531775 0.15782352 0.14115795 0.15091414 0.13954763
 0.16167825 0.16194887 0.15584227 0.1413033  0.16693421 0.14863433
 0.14909065 0.1346574  0.14402756 0.15499714 0.14759605 0.14501564
 0.14073141 0.11891351 0.16600384 0.14485729 0.15675256 0.14545171
 0.15290784 0.11966964 0.14602502 0.14318146 0.14792805 0.15347317
 0.15367251 0.15046261 0.14999819 0.15100376 0.15535004 0.16232776
 0.1517461  0.14987693 0.18085863 0.16073994 0.15075328 0.15453918
 0.15709709 0.15192658 0.15021949 0.14415173 0.16747033 0.15908421]
[17 29 16 38 24 20  7 14 25 33 30 28 22 41  9 21 45 43 48 44 46 39 34 36
 37 42 32 47 31 40 27 35  1  8 23 26  3 12 11 10  2  6 19 13  5 18  4 15]
shts_med
[{'regressor': [MLPRegressor(early_stopping=True, max_iter=2000)], 'scaler': [None, StandardScaler()], 'regressor__hidden_layer_sizes': [(100, 50)], 'regressor__activation': ['relu', 'tanh', 'logistic'], 'regressor__solver': ['adam'], 'regressor__learning_rate_init': [0.001, 0.01], 'regressor__alpha': [0.0001, 0.001], 'regressor__batch_size': ['auto', 32]}]
[-0.54322946 -0.56352574 -0.54493638 -0.56559823 -0.55225407 -0.55448705
 -0.51608492 -0.54317429 -0.54690398 -0.55123678 -0.53636412 -0.5412572
 -0.55488882 -0.57075981 -0.52406817 -0.53975742 -0.58840298 -0.58076347
 -0.58069777 -0.58241294 -0.58412978 -0.57508332 -0.56159361 -0.57223022
 -0.56673891 -0.57843199 -0.56384208 -0.56624886 -0.56750156 -0.58549342
 -0.56361921 -0.57842097 -0.50440283 -0.52790571 -0.53697887 -0.54610225
 -0.51680287 -0.53985852 -0.53241356 -0.53265587 -0.50701862 -0.5263825
 -0.54764725 -0.53840068 -0.51909154 -0.52107509 -0.51412264 -0.52157078]
[0.11562309 0.10520575 0.12069048 0.1013518  0.12184769 0.10607834
 0.10822354 0.10316379 0.11789123 0.10505813 0.11979237 0.0978337
 0.1254726  0.12399364 0.12075047 0.1211118  0.11100614 0.08960506
 0.11091262 0.11878996 0.12576165 0.09534857 0.11474556 0.11815744
 0.12469641 0.10263769 0.11663661 0.09700574 0.10750611 0.11521429
 0.11127194 0.1062791  0.11440874 0.11760296 0.12941799 0.11813244
 0.11202557 0.11680398 0.1240355  0.12201172 0.10465717 0.10799164
 0.11786807 0.09722908 0.13423668 0.1134568  0.12246767 0.1215333 ]
[21 31 22 34 27 28  4 20 24 26 14 19 29 38  9 17 48 44 43 45 46 40 30 39
 36 42 33 35 37 47 32 41  1 11 15 23  5 18 12 13  2 10 25 16  6  7  3  8]

*****************************************************************************
*                                                                           *
*                    JOB EFFICIENCY REPORT (seff 13087191)                   *
*                                                                           *
*****************************************************************************

Job ID: 13087191
Cluster: finisterrae3
User/Group: curso342/ulc
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 32
CPU Utilized: 3-00:00:45
CPU Efficiency: 99.48% of 3-00:23:28 core-walltime
Job Wall-clock time: 02:15:44
Memory Utilized: 8.26 GB
Memory Efficiency: 51.63% of 16.00 GB

 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ++   Memory Efficiency is too small. Please review the requested memory. ++
 ++ It seems that you do not need that much memory so we recommend        ++
 ++ requesting less memory in other similar jobs.                         ++
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
*****************************************************************************

